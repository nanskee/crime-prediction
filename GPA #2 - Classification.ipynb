{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-8GNNbp8tsF"
      },
      "source": [
        "## **GPA #2: Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group 1**\n",
        "\n",
        "*   Martina Cahya Pratiwi - 5026211144\n",
        "*   Ravarel Harsha Athalla -5026321048\n",
        "\n",
        "*   Thariq Abyan Arrayyan - 5026221217\n",
        "*   Najwa Iqna Auliya - 5026221059\n",
        "\n",
        "Link Video YT: https://youtu.be/_2ebgMNgPKU\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "anWzSsmxcvB9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R9Q0ykG8tsJ"
      },
      "source": [
        "### **1. Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Load the dataset\n",
        "data = pd.read_csv('cleaned_crime_data.csv')\n",
        "\n",
        "# 2. Drop unnecessary columns\n",
        "data = data.drop(columns=['Datetime','AREA NAME', 'LOCATION', 'Weapon Used Cd'])\n",
        "\n",
        "# 3. Transform categorical variables\n",
        "# Map 'Day of Week' to numbers (Monday = 1, Sunday = 7)\n",
        "day_of_week_mapping = {\n",
        "    'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4,\n",
        "    'Friday': 5, 'Saturday': 6, 'Sunday': 7\n",
        "}\n",
        "data['Day of Week'] = data['Day of Week'].map(day_of_week_mapping)\n",
        "\n",
        "# Map 'Time_of_Day' (Day = 0, Night = 1)\n",
        "time_of_day_mapping = {\n",
        "    'Day': 0,\n",
        "    'Night': 1\n",
        "}\n",
        "data['Time_of_Day'] = data['Time_of_Day'].map(time_of_day_mapping)\n",
        "\n",
        "# Map 'Vict Sex' (M = 1, X = 3, F = 2)\n",
        "vict_sex_mapping = {\n",
        "    'M': 1,\n",
        "    'X': 3,\n",
        "    'F': 2\n",
        "}\n",
        "data['Vict Sex'] = data['Vict Sex'].map(vict_sex_mapping)\n",
        "\n",
        "# 4. Encode 'Vict Descent' using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Vict Descent'] = label_encoder.fit_transform(data['Vict Descent'])\n",
        "\n",
        "# 5. Handle missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nMissing values in dataset:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "data['Premis Cd'].fillna(data['Premis Cd'].mode()[0], inplace=True)\n",
        "\n",
        "# 6. Display sample of transformed data\n",
        "print(\"\\nSample of transformed data:\")\n",
        "print(data.head())\n",
        "\n",
        "# 7. Check class distribution\n",
        "print(\"\\nInitial class distribution:\")\n",
        "print(data['Crm Cd'].value_counts())\n",
        "\n",
        "# 8. Prepare features and target\n",
        "X = data.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)  # Features\n",
        "y = data['Crm Cd']  # Class label\n",
        "\n",
        "# 9. Filter out rare classes (less than 5 instances)\n",
        "value_counts = y.value_counts()\n",
        "classes_to_keep = value_counts[value_counts >= 5].index\n",
        "data_filtered = data[data['Crm Cd'].isin(classes_to_keep)]\n",
        "\n",
        "# 10. Redefine X and y after filtering\n",
        "X = data_filtered.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)\n",
        "y = data_filtered['Crm Cd']\n",
        "\n",
        "# 11. Visualize class distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "y.value_counts().plot(kind='bar')\n",
        "plt.title('Distribution of Crime Classes')\n",
        "plt.xlabel('Crime Code')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 12. Split data with stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# 13. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame to maintain column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# 14. Implement 5-fold cross validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Function to display fold statistics\n",
        "def display_fold_stats(X, y, fold_number, indices):\n",
        "    fold_data = pd.DataFrame({'Crm Cd': y.iloc[indices]})\n",
        "    print(f\"\\nFold {fold_number} class distribution (proportions):\")\n",
        "    print(fold_data['Crm Cd'].value_counts(normalize=True) * 100)\n",
        "    return fold_data['Crm Cd'].value_counts(normalize=True)\n",
        "\n",
        "# Collect statistics for each fold\n",
        "fold_stats = []\n",
        "print(\"\\nCross-validation fold statistics:\")\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_scaled, y_train), 1):\n",
        "    fold_dist = display_fold_stats(X_train_scaled, y_train, fold, val_idx)\n",
        "    fold_stats.append(fold_dist)\n",
        "\n",
        "# Compare distributions across folds\n",
        "fold_distributions = pd.concat(fold_stats, axis=1)\n",
        "fold_distributions.columns = [f'Fold {i}' for i in range(1, 6)]\n",
        "print(\"\\nComparison of class distributions across folds:\")\n",
        "print(fold_distributions)\n",
        "\n",
        "# 15. Display overall statistics\n",
        "print(\"\\nOverall Data Split Statistics:\")\n",
        "print(\"\\nTraining set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n",
        "print(\"\\nTraining set class distribution (proportions):\")\n",
        "print(y_train.value_counts(normalize=True) * 100)\n",
        "print(\"\\nTest set class distribution (proportions):\")\n",
        "print(y_test.value_counts(normalize=True) * 100)\n",
        "\n",
        "# 16. Save processed datasets\n",
        "train_data = pd.DataFrame({\n",
        "    'y': y_train,\n",
        "    **{f'feature_{i}': X_train_scaled[col] for i, col in enumerate(X_train.columns)}\n",
        "})\n",
        "\n",
        "test_data = pd.DataFrame({\n",
        "    'y': y_test,\n",
        "    **{f'feature_{i}': X_test_scaled[col] for i, col in enumerate(X_test.columns)}\n",
        "})\n",
        "\n",
        "print(\"\\nProcessed datasets saved and ready for model training\")"
      ],
      "metadata": {
        "id": "S3Wv5l7k9Ps4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71ace9ea-20b1-4685-a7fb-76a4fe81c7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in dataset:\n",
            "Rpt Dist No              1\n",
            "Premis Cd                2\n",
            "Vict Age                 1\n",
            "Vict Age Standardized    1\n",
            "Vict Sex                 1\n",
            "dtype: int64\n",
            "\n",
            "Sample of transformed data:\n",
            "   Day of Week  Month  Hour  Year  Time_of_Day  AREA      LAT       LON  \\\n",
            "0            7      3    21  2020            1     7  34.0375 -118.3506   \n",
            "1            6      2    18  2020            1     1  34.0444 -118.2628   \n",
            "2            3     11    17  2020            0     3  34.0210 -118.3002   \n",
            "3            2      3    20  2020            1     9  34.1576 -118.4387   \n",
            "4            1      8    12  2020            0     6  34.0944 -118.3277   \n",
            "\n",
            "   Crm Cd                               Crm Cd Desc  Rpt Dist No  Premis Cd  \\\n",
            "0     510                          VEHICLE - STOLEN        784.0      101.0   \n",
            "1     330                     BURGLARY FROM VEHICLE        182.0      128.0   \n",
            "2     480                             BIKE - STOLEN        356.0      502.0   \n",
            "3     343  SHOPLIFTING-GRAND THEFT ($950.01 & OVER)        964.0      405.0   \n",
            "4     354                         THEFT OF IDENTITY        666.0      102.0   \n",
            "\n",
            "   Vict Age  Vict Age Standardized  Vict Sex  Vict Descent  \n",
            "0       0.0               0.000000       1.0            11  \n",
            "1      47.0               0.474747       1.0            11  \n",
            "2      19.0               0.191919       3.0            17  \n",
            "3      19.0               0.191919       1.0            11  \n",
            "4      28.0               0.282828       1.0             6  \n",
            "\n",
            "Initial class distribution:\n",
            "Crm Cd\n",
            "510    4701\n",
            "624    3543\n",
            "330    2814\n",
            "740    2791\n",
            "310    2771\n",
            "       ... \n",
            "906       1\n",
            "756       1\n",
            "470       1\n",
            "931       1\n",
            "485       1\n",
            "Name: count, Length: 120, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e69e40b7a2d5>:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Premis Cd'].fillna(data['Premis Cd'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACziUlEQVR4nOzdd3gU5ff38bPpPaSQhJCQhCIQeifSEQgQihQVG1VQxIL6lSICiqKIKCqCWMGGIKggohTpKgICIfQivSSAEAIIqef5g2fnl002IYswobxf18Wlmb139szMPWU/e++sRVVVAAAAAAAAABM5FXcBAAAAAAAAuP0QSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAHnppZfEYrGY8lrNmzeX5s2bG3+vWLFCLBaLzJkzx5TX7927t0RHR5vyWlfr/Pnz8sgjj0hYWJhYLBYZPHjwdX9NM/vA9XAzbFcAAGCLUAoAgFvM9OnTxWKxGP88PDwkPDxc4uPj5b333pNz585dk9c5duyYvPTSS5KYmHhN5nct3ci1FcVrr70m06dPl4EDB8qXX34pDz/8cKHts7OzZdq0adK8eXMJDAwUd3d3iY6Olj59+shff/1lUtXXR1pamrz88stSo0YN8fHxEU9PT6lataoMHTpUjh07VtzlAQCA/8CiqlrcRQAAgGtn+vTp0qdPHxkzZozExMRIZmamJCcny4oVK2TJkiVSpkwZ+fHHH6V69erGc7KysiQrK0s8PDyK/Dp//fWX1KtXT6ZNmya9e/cu8vMyMjJERMTNzU1ELo+UatGihcyePVu6d+9e5PlcbW2ZmZmSk5Mj7u7u1+S1roeGDRuKi4uL/Pbbb1dse/HiRenatassXLhQmjZtKh07dpTAwEA5cOCAfPvtt7J79245dOiQREREFDqfq+kD19u+ffukVatWcujQIbnnnnukcePG4ubmJklJSfLNN99IYGCg7N69W0Quj5RasWKFHDhwoHiLBgAAReZS3AUAAIDro127dlK3bl3j7+HDh8uyZcukQ4cO0qlTJ9mxY4d4enqKiIiLi4u4uFzfy4J///1XvLy8jDCquLi6uhbr6xfFiRMnJDY2tkhtn3/+eVm4cKFMnDgx39f8Ro8eLRMnTiz0+RcuXBBvb29T+oAjsrKypGvXrpKSkiIrVqyQxo0b2zw+duxYeeONN4qpOgAAcC3w9T0AAG4jLVu2lJEjR8rBgwflq6++Mqbbu5/QkiVLpHHjxlKiRAnx8fGRihUrygsvvCAil0c31atXT0RE+vTpY3xVcPr06SJy+b5RVatWlQ0bNkjTpk3Fy8vLeG7ee0pZZWdnywsvvCBhYWHi7e0tnTp1ksOHD9u0iY6OtjsqK/c8r1SbvXsPXbhwQZ577jmJjIwUd3d3qVixokyYMEHyDii3WCzyxBNPyNy5c6Vq1ari7u4uVapUkYULF9pf4XmcOHFC+vXrJ6GhoeLh4SE1atSQzz//3Hjcen+t/fv3y4IFC4zaCxr9c+TIEfnwww+ldevWdu875ezsLP/73/+MUVLW7bx9+3Z54IEHJCAgwAh77PUB6/LOnj1bYmNjxdPTU+Li4mTLli0iIvLhhx9K+fLlxcPDQ5o3b263zrVr10rbtm3F399fvLy8pFmzZvL7779fcV199913snnzZhkxYkS+QEpExM/PT8aOHVvoPCZMmCB33nmnBAUFiaenp9SpU8fuvcsK6+tWkyZNkipVqoiXl5cEBARI3bp1ZcaMGTZtjh49Kn379pXQ0FCjb3z22Wf5Xq8o8wIA4HZw43wcBgAATPHwww/LCy+8IIsXL5b+/fvbbbNt2zbp0KGDVK9eXcaMGSPu7u6yd+9eI0yoXLmyjBkzRkaNGiUDBgyQJk2aiIjInXfeaczjn3/+kXbt2kmPHj3koYcektDQ0ELrGjt2rFgsFhk6dKicOHFC3nnnHWnVqpUkJiYaI7qKoii15aaq0qlTJ1m+fLn069dPatasKYsWLZLnn39ejh49mm+k0W+//Sbff/+9PP744+Lr6yvvvfeedOvWTQ4dOiRBQUEF1nXx4kVp3ry57N27V5544gmJiYmR2bNnS+/evSU1NVWefvppqVy5snz55ZfyzDPPSEREhDz33HMiIlKyZEm78/zll18kKyvrivecyuuee+6RChUqyGuvvZYveMtr9erV8uOPP8qgQYNEROT111+XDh06yJAhQ2TKlCny+OOPy5kzZ2T8+PHSt29fWbZsmfHcZcuWSbt27aROnToyevRocXJykmnTpknLli1l9erVUr9+/QJf98cffxQRcXjZcnv33XelU6dO8uCDD0pGRobMnDlT7rnnHvnpp58kISFBRK7c10VEPv74Y3nqqaeke/fu8vTTT8ulS5ckKSlJ1q5dKw888ICIiKSkpEjDhg2NIK9kyZLyyy+/SL9+/SQtLc0IDYsyLwAAbhsKAABuKdOmTVMR0fXr1xfYxt/fX2vVqmX8PXr0aM19WTBx4kQVET158mSB81i/fr2KiE6bNi3fY82aNVMR0alTp9p9rFmzZsbfy5cvVxHR0qVLa1pamjH922+/VRHRd99915gWFRWlvXr1uuI8C6utV69eGhUVZfw9d+5cFRF99dVXbdp1795dLRaL7t2715gmIurm5mYzbfPmzSoiOmnSpHyvlds777yjIqJfffWVMS0jI0Pj4uLUx8fHZtmjoqI0ISGh0Pmpqj7zzDMqIrpp06YrtlX9v+18//33F/hYbiKi7u7uun//fmPahx9+qCKiYWFhNjUPHz5cRcRom5OToxUqVND4+HjNyckx2v37778aExOjrVu3LrTWWrVqqb+/f5GWSzX/drW+Vm4ZGRlatWpVbdmypTGtKH29c+fOWqVKlUJfv1+/flqqVCk9deqUzfQePXqov7+/UUtR5gUAwO2Cr+8BAHAb8vHxKfRX+EqUKCEiIvPmzZOcnJyreg13d3fp06dPkdv37NlTfH19jb+7d+8upUqVkp9//vmqXr+ofv75Z3F2dpannnrKZvpzzz0nqiq//PKLzfRWrVpJuXLljL+rV68ufn5+sm/fviu+TlhYmNx///3GNFdXV3nqqafk/PnzsnLlSodrT0tLExGxWW9F8dhjjxW57V133WXzdccGDRqIiEi3bt1sXtc63boeEhMTZc+ePfLAAw/IP//8I6dOnZJTp07JhQsX5K677pJVq1YV2rfS0tIcXq68co+wO3PmjJw9e1aaNGkiGzduNKYXpa+XKFFCjhw5IuvXr7f7uKrKd999Jx07dhRVNZb11KlTEh8fL2fPnjVe80rzAgDgdkIoBQDAbej8+fOFvuG/7777pFGjRvLII49IaGio9OjRQ7799luHAqrSpUs7dFPzChUq2PxtsVikfPny1/3X1A4ePCjh4eH51kflypWNx3MrU6ZMvnkEBATImTNnrvg6FSpUECcn28uvgl6nKPz8/ERECg0Y7YmJiSly27zL6+/vLyIikZGRdqdb18OePXtERKRXr15SsmRJm3+ffPKJpKeny9mzZwt8XT8/P4eXK6+ffvpJGjZsKB4eHhIYGCglS5aUDz74wOZ1i9LXhw4dKj4+PlK/fn2pUKGCDBo0yObrfSdPnpTU1FT56KOP8i2rNZg9ceJEkeYFAMDthHtKAQBwmzly5IicPXtWypcvX2AbT09PWbVqlSxfvlwWLFggCxculFmzZknLli1l8eLF4uzsfMXXceQ+UEWV90bcVtnZ2UWq6Voo6HX0Cvdmuh4qVaokIiJbtmyRmjVrFvl5jmybgpb3SuvBGuq8+eabBdbm4+NT4OtWqlRJNm3aJIcPH84XgBXF6tWrpVOnTtK0aVOZMmWKlCpVSlxdXWXatGk2NxUvSl+vXLmy7Nq1S3766SdZuHChfPfddzJlyhQZNWqUvPzyy8ayPvTQQ9KrVy+79VSvXl1E5IrzAgDgdsJIKQAAbjNffvmliIjEx8cX2s7JyUnuuusuefvtt2X79u0yduxYWbZsmSxfvlxECg6IrpZ1ZI2VqsrevXttvjoWEBAgqamp+Z6bd5SRI7VFRUXJsWPH8o3K2blzp/H4tRAVFSV79uzJN9rsv7xOu3btxNnZ2eaXFG8U1q84+vn5SatWrez+c3V1LfD5HTt2FBG56mX77rvvxMPDQxYtWiR9+/aVdu3aSatWrey2vVJfFxHx9vaW++67T6ZNmyaHDh2ShIQEGTt2rFy6dElKliwpvr6+kp2dXeCyhoSEFGleAADcTgilAAC4jSxbtkxeeeUViYmJkQcffLDAdqdPn843zTraJT09XUQuv7EWEbsh0dX44osvbIKhOXPmyPHjx6Vdu3bGtHLlysmff/4pGRkZxrSffvpJDh8+bDMvR2pr3769ZGdny/vvv28zfeLEiWKxWGxe/79o3769JCcny6xZs4xpWVlZMmnSJPHx8ZFmzZo5PM/IyEjp37+/LF68WCZNmpTv8ZycHHnrrbfkyJEj/6n2q1GnTh0pV66cTJgwQc6fP5/v8ZMnTxb6/O7du0u1atVk7NixsmbNmnyPnzt3TkaMGFHg852dncVisUh2drYx7cCBAzJ37lybdkXp6//884/N425ubhIbGyuqKpmZmeLs7CzdunWT7777TrZu3ZpvfrmX9UrzAgDgdsLX9wAAuEX98ssvsnPnTsnKypKUlBRZtmyZLFmyRKKiouTHH38UDw+PAp87ZswYWbVqlSQkJEhUVJScOHFCpkyZIhEREdK4cWMRuRwQlShRQqZOnSq+vr7i7e0tDRo0cOh+RbkFBgZK48aNpU+fPpKSkiLvvPOOlC9fXvr372+0eeSRR2TOnDnStm1buffee+Xvv/+Wr776yubG447W1rFjR2nRooWMGDFCDhw4IDVq1JDFixfLvHnzZPDgwfnmfbUGDBggH374ofTu3Vs2bNgg0dHRMmfOHPn999/lnXfeueqber/11lvy999/y1NPPSXff/+9dOjQQQICAuTQoUMye/Zs2blzp/To0eOaLIMjnJyc5JNPPpF27dpJlSpVpE+fPlK6dGk5evSoLF++XPz8/GT+/PkFPt/V1VW+//57adWqlTRt2lTuvfdeadSokbi6usq2bdtkxowZEhAQIGPHjrX7/ISEBHn77belbdu28sADD8iJEydk8uTJUr58eUlKSjLaFaWvt2nTRsLCwqRRo0YSGhoqO3bskPfff18SEhKM7TZu3DhZvny5NGjQQPr37y+xsbFy+vRp2bhxo/z6669G+FWUeQEAcNsovh/+AwAA18O0adNURIx/bm5uGhYWpq1bt9Z3331X09LS8j1n9OjRmvuyYOnSpdq5c2cNDw9XNzc3DQ8P1/vvv193795t87x58+ZpbGysuri4qIjotGnTVFW1WbNmBf7sfbNmzbRZs2bG38uXL1cR0W+++UaHDx+uISEh6unpqQkJCXrw4MF8z3/rrbe0dOnS6u7uro0aNdK//vor3zwLq61Xr14aFRVl0/bcuXP6zDPPaHh4uLq6umqFChX0zTff1JycHJt2IqKDBg3KV1NUVJT26tXL7vLmlpKSon369NHg4GB1c3PTatWqGXXlnV9CQsIV52eVlZWln3zyiTZp0kT9/f3V1dVVo6KitE+fPrpp0yajnXU7nzx5Mt888vYBVfvLu3//fhURffPNN22mW7fj7NmzbaZv2rRJu3btqkFBQeru7q5RUVF677336tKlS4u0bGfOnNFRo0ZptWrV1MvLSz08PLRq1ao6fPhwPX78uNHO3nb99NNPtUKFCuru7q6VKlXSadOmXVVf//DDD7Vp06bGMpQrV06ff/55PXv2rM3rpaSk6KBBgzQyMlJdXV01LCxM77rrLv3oo48cnhcAALcDi2ox3JUTAAAAAAAAtzXuKQUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdC7FXcDNICcnR44dOya+vr5isViKuxwAAAAAAIBioapy7tw5CQ8PFyen/zbWiVCqCI4dOyaRkZHFXQYAAAAAAMAN4fDhwxIREfGf5kEoVQS+vr4icnmF+/n5FXM1AAAAAAAAxSMtLU0iIyONrOS/IJQqAutX9vz8/AilAAAAAADAbe9a3N6IG50DAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdC7FXcDNKHrYArvTD4xLMLkSAAAAAACAmxMjpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOlumFBq3LhxYrFYZPDgwca0S5cuyaBBgyQoKEh8fHykW7dukpKSYvO8Q4cOSUJCgnh5eUlISIg8//zzkpWVZdNmxYoVUrt2bXF3d5fy5cvL9OnTTVgiAAAAAAAAFOSGCKXWr18vH374oVSvXt1m+jPPPCPz58+X2bNny8qVK+XYsWPStWtX4/Hs7GxJSEiQjIwM+eOPP+Tzzz+X6dOny6hRo4w2+/fvl4SEBGnRooUkJibK4MGD5ZFHHpFFixaZtnwAAAAAAACwVeyh1Pnz5+XBBx+Ujz/+WAICAozpZ8+elU8//VTefvttadmypdSpU0emTZsmf/zxh/z5558iIrJ48WLZvn27fPXVV1KzZk1p166dvPLKKzJ58mTJyMgQEZGpU6dKTEyMvPXWW1K5cmV54oknpHv37jJx4sRiWV4AAAAAAADcAKHUoEGDJCEhQVq1amUzfcOGDZKZmWkzvVKlSlKmTBlZs2aNiIisWbNGqlWrJqGhoUab+Ph4SUtLk23bthlt8s47Pj7emIc96enpkpaWZvMPAAAAAAAA145Lcb74zJkzZePGjbJ+/fp8jyUnJ4ubm5uUKFHCZnpoaKgkJycbbXIHUtbHrY8V1iYtLU0uXrwonp6e+V779ddfl5dffvmqlwsAAAAAAACFK7aRUocPH5ann35avv76a/Hw8CiuMuwaPny4nD171vh3+PDh4i4JAAAAAADgllJsodSGDRvkxIkTUrt2bXFxcREXFxdZuXKlvPfee+Li4iKhoaGSkZEhqampNs9LSUmRsLAwEREJCwvL92t81r+v1MbPz8/uKCkREXd3d/Hz87P5BwAAAAAAgGun2EKpu+66S7Zs2SKJiYnGv7p168qDDz5o/L+rq6ssXbrUeM6uXbvk0KFDEhcXJyIicXFxsmXLFjlx4oTRZsmSJeLn5yexsbFGm9zzsLaxzgMAAAAAAADmK7Z7Svn6+krVqlVtpnl7e0tQUJAxvV+/fvLss89KYGCg+Pn5yZNPPilxcXHSsGFDERFp06aNxMbGysMPPyzjx4+X5ORkefHFF2XQoEHi7u4uIiKPPfaYvP/++zJkyBDp27evLFu2TL799ltZsGCBuQsMAAAAAAAAQ7He6PxKJk6cKE5OTtKtWzdJT0+X+Ph4mTJlivG4s7Oz/PTTTzJw4ECJi4sTb29v6dWrl4wZM8ZoExMTIwsWLJBnnnlG3n33XYmIiJBPPvlE4uPji2ORAAAAAAAAICIWVdXiLuJGl5aWJv7+/nL27Fnx8/OT6GH2R1kdGJdgcmUAAAAAAADmyZuR/BfFdk8pAAAAAAAA3L4IpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYzqW4C7gdRA9bkG/agXEJxVAJAAAAAADAjYGRUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHTFGkp98MEHUr16dfHz8xM/Pz+Ji4uTX375xXj80qVLMmjQIAkKChIfHx/p1q2bpKSk2Mzj0KFDkpCQIF5eXhISEiLPP/+8ZGVl2bRZsWKF1K5dW9zd3aV8+fIyffp0MxYPAAAAAAAABSjWUCoiIkLGjRsnGzZskL/++ktatmwpnTt3lm3btomIyDPPPCPz58+X2bNny8qVK+XYsWPStWtX4/nZ2dmSkJAgGRkZ8scff8jnn38u06dPl1GjRhlt9u/fLwkJCdKiRQtJTEyUwYMHyyOPPCKLFi0yfXkBAAAAAABwmUVVtbiLyC0wMFDefPNN6d69u5QsWVJmzJgh3bt3FxGRnTt3SuXKlWXNmjXSsGFD+eWXX6RDhw5y7NgxCQ0NFRGRqVOnytChQ+XkyZPi5uYmQ4cOlQULFsjWrVuN1+jRo4ekpqbKwoULi1RTWlqa+Pv7y9mzZ8XPz0+ihy2w2+7AuAS70+21L6gtAAAAAADAjSpvRvJf3DD3lMrOzpaZM2fKhQsXJC4uTjZs2CCZmZnSqlUro02lSpWkTJkysmbNGhERWbNmjVSrVs0IpERE4uPjJS0tzRhttWbNGpt5WNtY52FPenq6pKWl2fwDAAAAAADAtVPsodSWLVvEx8dH3N3d5bHHHpMffvhBYmNjJTk5Wdzc3KREiRI27UNDQyU5OVlERJKTk20CKevj1scKa5OWliYXL160W9Prr78u/v7+xr/IyMhrsagAAAAAAAD4/4o9lKpYsaIkJibK2rVrZeDAgdKrVy/Zvn17sdY0fPhwOXv2rPHv8OHDxVoPAAAAAADArcaluAtwc3OT8uXLi4hInTp1ZP369fLuu+/KfffdJxkZGZKammozWiolJUXCwsJERCQsLEzWrVtnMz/rr/PlbpP3F/tSUlLEz89PPD097dbk7u4u7u7u12T5AAAAAAAAkF+xj5TKKycnR9LT06VOnTri6uoqS5cuNR7btWuXHDp0SOLi4kREJC4uTrZs2SInTpww2ixZskT8/PwkNjbWaJN7HtY21nkAAAAAAADAfMU6Umr48OHSrl07KVOmjJw7d05mzJghK1askEWLFom/v7/069dPnn32WQkMDBQ/Pz958sknJS4uTho2bCgiIm3atJHY2Fh5+OGHZfz48ZKcnCwvvviiDBo0yBjp9Nhjj8n7778vQ4YMkb59+8qyZcvk22+/lQUL7P+CHgAAAAAAAK6/Yg2lTpw4IT179pTjx4+Lv7+/VK9eXRYtWiStW7cWEZGJEyeKk5OTdOvWTdLT0yU+Pl6mTJliPN/Z2Vl++uknGThwoMTFxYm3t7f06tVLxowZY7SJiYmRBQsWyDPPPCPvvvuuREREyCeffCLx8fGmLy8AAAAAAAAus6iqFncRN7q0tDTx9/eXs2fPip+fn0QPsz/K6sC4BLvT7bUvqC0AAAAAAMCNKm9G8l/ccPeUAgAAAAAAwK2PUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDqX4i4AtqKHLcg37cC4hGKoBAAAAAAA4PphpBQAAAAAAABMx0ipm5i9UVUijKwCAAAAAAA3PkZKAQAAAAAAwHSMlLpNMKoKAAAAAADcSBgpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAw3VWFUmXLlpV//vkn3/TU1FQpW7bsfy4KAAAAAAAAt7arCqUOHDgg2dnZ+aanp6fL0aNH/3NRAAAAAAAAuLW5ONL4xx9/NP5/0aJF4u/vb/ydnZ0tS5culejo6GtWHIpP9LAF+aYdGJdQDJUAAAAAAIBbkUOh1N133y0iIhaLRXr16mXzmKurq0RHR8tbb711zYoDAAAAAADArcmhUConJ0dERGJiYmT9+vUSHBx8XYoCAAAAAADArc2hUMpq//7917oOAAAAAAAA3EauKpQSEVm6dKksXbpUTpw4YYygsvrss8/+c2EAAAAAAAC4dV1VKPXyyy/LmDFjpG7dulKqVCmxWCzXui4AAAAAAADcwq4qlJo6dapMnz5dHn744WtdDwAAAAAAAG4DTlfzpIyMDLnzzjuvdS0AAAAAAAC4TVxVKPXII4/IjBkzrnUtAAAAAAAAuE1c1df3Ll26JB999JH8+uuvUr16dXF1dbV5/O23374mxQEAAAAAAODWdFWhVFJSktSsWVNERLZu3WrzGDc9BwAAAAAAwJVcVSi1fPnya10HAAAAAAAAbiNXdU8pAAAAAAAA4L+4qpFSLVq0KPRresuWLbvqggAAAAAAAHDru6pQyno/KavMzExJTEyUrVu3Sq9eva5FXQAAAAAAALiFXVUoNXHiRLvTX3rpJTl//vx/KggAAAAAAAC3vmt6T6mHHnpIPvvss2s5SwAAAAAAANyCrmkotWbNGvHw8LiWswQAAAAAAMAt6Kq+vte1a1ebv1VVjh8/Ln/99ZeMHDnymhQGAAAAAACAW9dVhVL+/v42fzs5OUnFihVlzJgx0qZNm2tSGAAAAAAAAG5dVxVKTZs27VrXgZtY9LAFdqcfGJdgciUAAAAAAOBmcVWhlNWGDRtkx44dIiJSpUoVqVWr1jUpCgAAAAAAALe2qwqlTpw4IT169JAVK1ZIiRIlREQkNTVVWrRoITNnzpSSJUteyxpxC2FUFQAAAAAAELnKUOrJJ5+Uc+fOybZt26Ry5coiIrJ9+3bp1auXPPXUU/LNN99c0yJx+7IXYhFgAQAAAABw87uqUGrhwoXy66+/GoGUiEhsbKxMnjyZG50DAAAAAADgipyu5kk5OTni6uqab7qrq6vk5OT856IAAAAAAABwa7uqUKply5by9NNPy7Fjx4xpR48elWeeeUbuuuuua1YcAAAAAAAAbk1XFUq9//77kpaWJtHR0VKuXDkpV66cxMTESFpamkyaNOla1wgAAAAAAIBbzFXdUyoyMlI2btwov/76q+zcuVNERCpXriytWrW6psUBAAAAAADg1uTQSKlly5ZJbGyspKWlicVikdatW8uTTz4pTz75pNSrV0+qVKkiq1evvl61AgAAAAAA4BbhUCj1zjvvSP/+/cXPzy/fY/7+/vLoo4/K22+/fc2KAwAAAAAAwK3JoVBq8+bN0rZt2wIfb9OmjWzYsOE/FwUAAAAAAIBbm0OhVEpKiri6uhb4uIuLi5w8efI/FwUAAAAAAIBbm0OhVOnSpWXr1q0FPp6UlCSlSpX6z0UBAAAAAADg1uZQKNW+fXsZOXKkXLp0Kd9jFy9elNGjR0uHDh2uWXEAAAAAAAC4Nbk40vjFF1+U77//Xu644w554oknpGLFiiIisnPnTpk8ebJkZ2fLiBEjrkuhAAAAAAAAuHU4FEqFhobKH3/8IQMHDpThw4eLqoqIiMVikfj4eJk8ebKEhoZel0IBAAAAAABw63AolBIRiYqKkp9//lnOnDkje/fuFVWVChUqSEBAwPWoDwAAAAAAALcgh0Mpq4CAAKlXr961rAUAAAAAAAC3CYdudA4AAAAAAABcC4RSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAEznUtwFANdK9LAFdqcfGJdgciUAAAAAAOBKGCkFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADBdsYZSr7/+utSrV098fX0lJCRE7r77btm1a5dNm0uXLsmgQYMkKChIfHx8pFu3bpKSkmLT5tChQ5KQkCBeXl4SEhIizz//vGRlZdm0WbFihdSuXVvc3d2lfPnyMn369Ou9eAAAAAAAAChAsYZSK1eulEGDBsmff/4pS5YskczMTGnTpo1cuHDBaPPMM8/I/PnzZfbs2bJy5Uo5duyYdO3a1Xg8OztbEhISJCMjQ/744w/5/PPPZfr06TJq1Cijzf79+yUhIUFatGghiYmJMnjwYHnkkUdk0aJFpi4vAAAAAAAALnMpzhdfuHChzd/Tp0+XkJAQ2bBhgzRt2lTOnj0rn376qcyYMUNatmwpIiLTpk2TypUry59//ikNGzaUxYsXy/bt2+XXX3+V0NBQqVmzprzyyisydOhQeemll8TNzU2mTp0qMTEx8tZbb4mISOXKleW3336TiRMnSnx8vOnLDQAAAAAAcLu7oe4pdfbsWRERCQwMFBGRDRs2SGZmprRq1cpoU6lSJSlTpoysWbNGRETWrFkj1apVk9DQUKNNfHy8pKWlybZt24w2uedhbWOdBwAAAAAAAMxVrCOlcsvJyZHBgwdLo0aNpGrVqiIikpycLG5ublKiRAmbtqGhoZKcnGy0yR1IWR+3PlZYm7S0NLl48aJ4enraPJaeni7p6enG32lpaf99AQEAAAAAAGC4YUZKDRo0SLZu3SozZ84s7lLk9ddfF39/f+NfZGRkcZcEAAAAAABwS7khQqknnnhCfvrpJ1m+fLlEREQY08PCwiQjI0NSU1Nt2qekpEhYWJjRJu+v8Vn/vlIbPz+/fKOkRESGDx8uZ8+eNf4dPnz4Py8jAAAAAAAA/k+xhlKqKk888YT88MMPsmzZMomJibF5vE6dOuLq6ipLly41pu3atUsOHTokcXFxIiISFxcnW7ZskRMnThhtlixZIn5+fhIbG2u0yT0PaxvrPPJyd3cXPz8/m38AAAAAAAC4dor1nlKDBg2SGTNmyLx588TX19e4B5S/v794enqKv7+/9OvXT5599lkJDAwUPz8/efLJJyUuLk4aNmwoIiJt2rSR2NhYefjhh2X8+PGSnJwsL774ogwaNEjc3d1FROSxxx6T999/X4YMGSJ9+/aVZcuWybfffisLFiwotmUHAAAAAAC4nRXrSKkPPvhAzp49K82bN5dSpUoZ/2bNmmW0mThxonTo0EG6desmTZs2lbCwMPn++++Nx52dneWnn34SZ2dniYuLk4ceekh69uwpY8aMMdrExMTIggULZMmSJVKjRg1566235JNPPpH4+HhTlxcAAAAAAACXFetIKVW9YhsPDw+ZPHmyTJ48ucA2UVFR8vPPPxc6n+bNm8umTZscrhEAAAAAAADX3g1xo3MAAAAAAADcXgilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJjOpbgLAIpD9LAFdqcfGJdgciUAAAAAANyeGCkFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAd95QCisDePai4/xQAAAAAAFePkVIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANO5FHcBwK0metiCfNMOjEsohkoAAAAAALhxMVIKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYrlhDqVWrVknHjh0lPDxcLBaLzJ071+ZxVZVRo0ZJqVKlxNPTU1q1aiV79uyxaXP69Gl58MEHxc/PT0qUKCH9+vWT8+fP27RJSkqSJk2aiIeHh0RGRsr48eOv96IBAAAAAACgEMUaSl24cEFq1KghkydPtvv4+PHj5b333pOpU6fK2rVrxdvbW+Lj4+XSpUtGmwcffFC2bdsmS5YskZ9++klWrVolAwYMMB5PS0uTNm3aSFRUlGzYsEHefPNNeemll+Sjjz667ssHAAAAAAAA+1yK88XbtWsn7dq1s/uYqso777wjL774onTu3FlERL744gsJDQ2VuXPnSo8ePWTHjh2ycOFCWb9+vdStW1dERCZNmiTt27eXCRMmSHh4uHz99deSkZEhn332mbi5uUmVKlUkMTFR3n77bZvwCgAAAAAAAOYp1lCqMPv375fk5GRp1aqVMc3f318aNGgga9askR49esiaNWukRIkSRiAlItKqVStxcnKStWvXSpcuXWTNmjXStGlTcXNzM9rEx8fLG2+8IWfOnJGAgABTlwvILXrYArvTD4xLMLkSAAAAAADMdcOGUsnJySIiEhoaajM9NDTUeCw5OVlCQkJsHndxcZHAwECbNjExMfnmYX3MXiiVnp4u6enpxt9paWn/cWkAAAAAAACQG7++Z8frr78u/v7+xr/IyMjiLgkAAAAAAOCWcsOGUmFhYSIikpKSYjM9JSXFeCwsLExOnDhh83hWVpacPn3apo29eeR+jbyGDx8uZ8+eNf4dPnz4vy8QAAAAAAAADDdsKBUTEyNhYWGydOlSY1paWpqsXbtW4uLiREQkLi5OUlNTZcOGDUabZcuWSU5OjjRo0MBos2rVKsnMzDTaLFmyRCpWrFjg/aTc3d3Fz8/P5h8AAAAAAACunWINpc6fPy+JiYmSmJgoIpdvbp6YmCiHDh0Si8UigwcPlldffVV+/PFH2bJli/Ts2VPCw8Pl7rvvFhGRypUrS9u2baV///6ybt06+f333+WJJ56QHj16SHh4uIiIPPDAA+Lm5ib9+vWTbdu2yaxZs+Tdd9+VZ599tpiWGgAAAAAAAMV6o/O//vpLWrRoYfxtDYp69eol06dPlyFDhsiFCxdkwIABkpqaKo0bN5aFCxeKh4eH8Zyvv/5annjiCbnrrrvEyclJunXrJu+9957xuL+/vyxevFgGDRokderUkeDgYBk1apQMGDDAvAUFAAAAAACAjWINpZo3by6qWuDjFotFxowZI2PGjCmwTWBgoMyYMaPQ16levbqsXr36qusEbgTRwxbYnX5gXILJlQAAAAAA8N/dsPeUAgAAAAAAwK2LUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDqX4i4AwPURPWxBvmkHxiUUQyUAAAAAAOTHSCkAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjl/fA2D3l/pE+LU+AAAAAMD1w0gpAAAAAAAAmI5QCgAAAAAAAKbj63sAHMJX/QAAAAAA1wIjpQAAAAAAAGA6QikAAAAAAACYjq/vAbiu7H3dj6/6AQAAAAAYKQUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdC7FXQAAWEUPW2B3+oFxCSZXAgAAAAC43hgpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwnUtxFwAAVyN62AK70w+MSzC5EgAAAADA1WCkFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdC7FXQAAmCF62IJ80w6MS/jPbQEAAAAAV4eRUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHQuxV0AANzMooctsDv9wLiE/9QWAAAAAG51jJQCAAAAAACA6QilAAAAAAAAYDq+vgcANyh7X/fjq34AAAAAbhWMlAIAAAAAAIDpGCkFALcAbqIOAAAA4GZDKAUAtxlHAyy+RggAAADgeiCUAgBcM4zYAgAAAFBUhFIAgGLBiC0AAADg9saNzgEAAAAAAGA6RkoBAG45jKoCAAAAbnyEUgCA2xr3wQIAAACKB6EUAABFRIAFAAAAXDvcUwoAAAAAAACmY6QUAADXCfe2AgAAAApGKAUAwA2ArwYCAADgdkMoBQDATcbRAIsRWwAAALgREUoBAACDI4EXo7sAAADwXxBKAQAAUzBiCwAAALkRSgEAgBuOIwEWI7YAAABuToRSAADgtkGABQAAcOMglAIAACgAI7YAAACuH0IpAAAAk13PX1DkZvUAAOBmQSgFAACAIvmv4RhhFwAAyO22CqUmT54sb775piQnJ0uNGjVk0qRJUr9+/eIuCwAA4LbG6C4AAG5Pt00oNWvWLHn22Wdl6tSp0qBBA3nnnXckPj5edu3aJSEhIcVdHgAAAK6DG+WrjzdjHQAAXG+3TSj19ttvS//+/aVPnz4iIjJ16lRZsGCBfPbZZzJs2LBirg4AAAC4sdyMQdrNWAcA3M5ui1AqIyNDNmzYIMOHDzemOTk5SatWrWTNmjXFWBkAAACA25nZ4ditFOgxUhC4+d0WodSpU6ckOztbQkNDbaaHhobKzp0787VPT0+X9PR04++zZ8+KiEhaWpqIiOSk/2v3dayP52Wv/fVqW1B7s2umjqtvW1D723Xd3Sh13Iw1U8fVty2o/e267m6UOm7Gmqnj6tsW1P52XXc3Sh03Y83UcfVtC2p/O6y7qqMX2Z2+9eX4/9S2oPbXq21B7c2u+Xau41Zk3W9U9T/Py6LXYi43uGPHjknp0qXljz/+kLi4OGP6kCFDZOXKlbJ27Vqb9i+99JK8/PLLZpcJAAAAAABwUzh8+LBERET8p3ncFiOlgoODxdnZWVJSUmymp6SkSFhYWL72w4cPl2effdb4OycnR06fPi1BQUFisViM6WlpaRIZGSmHDx8WPz+/QmtwpO31nPfNWMfNWDN13Pw1U8fNXzN13Pw1U8fNXzN13Pw1U8fNXzN13Pw1U8fNX/OtVoeqyrlz5yQ8PPyKr3clt0Uo5ebmJnXq1JGlS5fK3XffLSKXg6alS5fKE088ka+9u7u7uLu720wrUaJEgfP38/Mr0sZ3tO31nPfNWMfNWDN1XH1b6rgx67gZa6aOq29LHTdmHTdjzdRx9W2p48as42asmTquvi113Jh13Iw130p1+Pv7F/m1CnNbhFIiIs8++6z06tVL6tatK/Xr15d33nlHLly4YPwaHwAAAAAAAMxz24RS9913n5w8eVJGjRolycnJUrNmTVm4cGG+m58DAAAAAADg+rttQikRkSeeeMLu1/Wulru7u4wePTrfV/3+a9vrOe+bsY6bsWbquPlrpo6bv2bquPlrpo6bv2bquPlrpo6bv2bquPlrpo6bv+bboY6rdVv8+h4AAAAAAABuLE7FXQAAAAAAAABuP4RSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAG5qWVlZxV0CAOAGx7kCAG5MhFLXmKpKUX7Q8MKFCw7P93q1L2rNV1NHUe3fv1+WLl16XeYNcxw5ckTWr19fpLaXLl2S1NTUIs87Ozv7KqsqnCP9zsw+eq32s2PHjsnu3buvybz+q6Iuk6N9Y8eOHTJixIhrXoejMjMz5eLFi1f1XEeP14VJTU2Vs2fPXlUd//W1/8vzcnJyrmrehTlw4ICsXbv2ms/Xqqg1m7EfFmUdb9u2TcaPH39N53k19u7dKz/88MN1mbejHFnG69FHRUROnjwpJ06cuKrnFqX+oi7j9ewf12vd5VVYTY6eK4oyz9yu9jqlsPk7el65mn3rei+fo65Uz/U6D2VkZIjI9emrjpyXc3JybphziyPvD/M+72ZzLa/DHOFoHvBf9sPrtV2u1XxdrslcIOnp6eLu7i5ZWVni6upaaNsdO3ZIly5d5NVXX5Xu3bsX2jYrK0tcXFwkJydHnJ2dJScnR5ycCs4SHWnvSM0pKSkSGhoqFotFVFUsFkuBbQ8cOCBLliwRJycniYyMlDZt2hQ676SkJOnQoYO0bdtWYmNjpVSpUtdk3o7W8ffff8ucOXMkMzNToqOj5aGHHiqw7d69e+Xw4cPSvHnzQteF1ZXW2dW2d6TmY8eOycaNGyUjI0Oio6Oldu3a16zmpKQk6d69u3Tt2lXKlCkjoaGhBbbdvn27DBs2TA4ePChRUVEydOhQadSokd22p06dkuDgYHF2dpbs7GxxdnYucL6OrAtrzUXtd460dbSOAwcOyLx58+TMmTNSvnx5eeihhwpc74706U2bNknr1q1l+vTpcscddxRag1VRt/nu3bvls88+k3PnzknZsmWlV69eEhwcbLetI8ckR/qGiMiWLVskLi5O/v33X4mLi5O77767wLaO1PH333/Ld999J5cuXZLSpUtLnz59Cj3u7tixQ1599VU5cOCAVKpUSV566SWJjIy029aR7f3333/LF198IadOnZLY2FgZNGhQodtnz549Eh8fLwMHDpQBAwaIv79/gW0zMjLEzc3NOA8Utn85uu4cqTk1NVVKlCghTk5OVzy/OVJzYmKiNG/eXN5//31p0KBBgfPMXXdR91tHanZ0P3Rk37p48aK4u7tLZmamuLu7Fzrf3PvKnXfeKY0bNy60/Z49e2Ty5Mly6NAhqVatmrz00kuF9tOirrukpCSJj4+XNm3aSP369aV06dIFtnX0WOrIust7rCtsOzqyvR2teePGjdK+fXuZM2eOhISEFNr28OHDsnz5crlw4YKULVtW4uPjC923rPtHdna2sf8WVLsj/cOR60FH1p2IY9vQkfXhyLlC5PK+5eLiIhkZGeLt7V3oscaR6xRHanbkvCLi2L4lUvT+4cjyiTh2neLI+nBknz1w4ID88MMPcv78ealYsaLce++9hfbTrVu3yv333y/Tp0+XOnXqFDpvR6//HTkv79q1SyZOnCiHDx+WGjVqyNixYwt8DUfOLY4elxx5f+jIunZk/3a0bkfaOtLvHL2msfZ/EZHQ0FDp1KlTgW0dyQMc3Q8dqduRa15Hz0MOUfxnW7du1S5dumirVq00Pj5eV65cqenp6QW2HzZsmFosFg0MDNTZs2cX2G779u3at29f7dq1qw4YMEB37txZaB2OtHek5j179qjFYtFu3boZ03Jycuy2TUpK0qCgIG3YsKGWK1dOfXx89JFHHtFjx47Zbb9v3z4NDQ3V//3vf4Uum6PzdrSOLVu2qL+/vzZr1kzr1aun7u7umpCQoH/++We+tomJiWqxWPTDDz+8Ys0HDhzQrVu3qmrB6+xq2ztSc1JSkpYtW1br16+vwcHBWrdu3QL73p49e3TdunWqqpqdnX3Fmvfs2aMlS5bUZ599VjMzMwttu23bNg0MDNQBAwboxx9/rJUrV7bpV7lt375dPTw8tF+/fsa0rKwsu20dWReqjvU7R9o6WkdSUpKWLl1aW7VqZbQfM2ZMgW2L2qcTExPV29tbBw8ebHdeefuWI9t827Zt6ufnp23bttVOnTqpn5+fNm/eXGfNmpVvvo4ckxzpG9Zl9PDw0P79+2vHjh310UcfLbB+R+rYsmWLBgUFafv27bVz587q7e2tLVu21MWLF9vdJ7du3apBQUH68MMP6yuvvKJBQUH62GOP2Z23I9t78+bNGhYWpgkJCdqhQwd1cXHR9957r8C6VVXffvtttVgs6ufnpxMmTNC0tDS77Xbs2KEPPfSQtmvXTjt27KgHDx4scJ6OrDtHa96+fbvGxMToyJEjjWkF9T9Harb2/2eeeabANrk5st86UrOj+6Ej+9aWLVv0rrvu0oYNG2qVKlX0yy+/1KNHjxZYh4eHhz744INar149feWVV1S14ONpUlKShoSEaLdu3bRfv37q7e2tI0aMsNvWkXV38OBBLV269HU5ljqy7vbs2aOjR4/W3r176xtvvKHJycmqav+c68j2drTmxMRE9fHx0aefftru47nrSUpK0jJlymiTJk20fPnyWrp0aZ0yZYrd56mq7tq1S5966int1q2bDhgwwNhf7NXuSP/Yvn27WiwW7dixo90687Yt6rpTdWwbOrI+HDlXWOvu3LmzNmnSRKtWrarbt28vsGZHrlMcqdmR84qqY/uWatH7hyPLZ11GR67Ti7o+HNlnN2/erOHh4cbxMSwsTGfOnFno+ujfv79aLBYNCQkxroXsLacj1/9WRT0vb9myRYODg/Wee+7Rxx57TL29vfWll16y29aRc4ujxyVH3h86sq4d2b8drdvR90NF7XeOXtNYz5133XWX3nnnnert7a0PPPBAgccQR/IAR/ZDR+p25JrX0fOQowil/qPdu3ern5+fDhgwQJ9//nnt3r27WiwWHT16dIEXzXPmzNHBgwfrK6+8om5ubjpr1izjMWsH2Llzp/r6+mqvXr30/vvv15YtW6qHh4d++umneuHChXzzdKS9ozWvXr1aS5UqpQEBAdqhQ4cC18W5c+c0Li5On3zySVVVPX78uP7yyy8aGBiobdu21b179+Z7zmeffab33HOPqqpmZmbquHHjdODAgTps2DDdsGGDsT4cmbejdfz7778aHx+vjz/+uKqqXrx4Ubdv367ly5fXpk2b6rJly4y2mzdvVm9vb33++eftroPcJ/SdO3dqYGCgxsTE6Pr161W18KDJkfaO1Lx3716NiIjQIUOGaGpqqv7111/aq1cv7du3r2ZlZdm8xq5du9TT01MtFosuX7483zLZM378eH3wwQdV9fJBcsqUKTpq1Ch96623jAsHVdULFy5ohw4dbC7AFyxYoPfee6/+888/NoHWkSNHtH79+lq7dm0NDw/XAQMGGI/lPRA7si6sitrvHGnraB0HDhzQcuXK6ZAhQzQnJ0fT0tL0ww8/1MqVK+vff/9t09aRPr1t2zb19fU1+mhWVpauXr1af/75Z125cmW+deHINk9PT9d7771XH3nkEWPa0aNHtVWrVnrnnXfqZ599dlXHMEf6hqrqhg0b1NfXV1944QVVVZ00aZK6urrqrl278tXsSB2pqanaoEEDHTJkiDFt69at6uHhoY0bN9bvv//epn1aWpo2b95cn3vuOWPaRx99pAMGDNCLFy/atHVke+/evVujoqJ02LBhmpOToxcuXNCePXvq66+/nm/5cluzZo0OHTpUp0yZohaLRcePH29cTFq3S1JSkgYEBOiAAQP0ueee07vuuks7deqkGRkZNu0cXXeO1nzo0CGtWbOmVqhQQatWraovv/yy8Vje/udozd7e3sY2zMzM1J9++kk///xz/e677/LV4ch+60jNju6Hjuxbf//9twYEBOigQYN00qRJ+uSTTxrr56+//rKZ74YNG9THx8fYV0aOHKn+/v56/PjxfDVY5x0TE6PDhg0zpo0YMcJuwOfoMW/evHnaqVMnVVXNyMjQESNGaI8ePbRv3776ww8/GOvQ0fk6su6SkpI0ODhYH3jgAW3atKk2atRI7733Xj1//ny+5XNkeztac1JSkvr7+xv9Izs7W7ds2aJr1qzRbdu2Ge1ycnJ03759GhUVpUOGDNFLly7p/v379cUXX9Q2bdro6dOn7QaWQUFB2qdPH+3Ro4e2aNFC69Wrp//880++ZXSkfxw/flwbNWqkzZo107CwML377rtt6rzadafq2DZ0ZH04cq6wrjvrvjVx4kTt0KGDVq1a1Tie567dkesUR2p25LxiVdR9y7qMRekfjiyfqmPXKY6sD0f22V27dmnp0qV12LBhmpWVpYcOHdLWrVvrJ598Yne9Wb399ts6cOBAHTRokPr6+toNMxy5/s+tKOflM2fOaL169WyuPUaMGGFzHLZy5Nzi6HHJkfeHjqxrR/ZvR+t2pK0j/c7Ra5pTp05ptWrVdOjQoap6+bp2/vz56uzsrF26dNENGzbke05R8gBH90NH6nbkmtfR89DVIJT6j6wbJLf33ntPg4KCdOjQoTZvyq1WrFhhnOQef/xx9fDw0MWLF+v//vc/nTx5sqqqDho0yDjBqP7fScbJyUnfe+8942LcypH2jtSck5Oj69at08aNG+vy5cs1PDxcO3fubDx+6NAh4/8vXryotWvXzpeS79q1S4ODg/Xuu+/OtwP973//M+pu0qSJxsXF6X333adlypTRRo0a6ddff+3wvK+mjkaNGun48eNVVY03wEePHtXq1atrs2bN9PDhw7pt2zb18PAwLs6zs7N15syZOnbsWJ0yZYrxKXV2drYeP35cW7Vqpc2bN9dOnTpp7dq1de3atcY6zcvR9kWtOT09XZ999lm99957bT7p+PTTTzUoKEhPnTplTDt58qR26NBBExIS9IEHHtCAgABdunSpsUwFeeSRR/TRRx/VnJwcvfPOO7V+/frasmVL9fX11RYtWujvv/+uqpf7ZNOmTfXNN980nvvMM89omTJlNCoqSlu2bKmvvvqqZmVl6aeffqpdu3bV5cuX67Rp0zQ0NNTmQJw3pCjKusitqP3O0bZFrSM7O1vfeOMNbdu2rZ49e9Z4/l9//aXBwcH5PlUpap/OysrSVq1aqZ+fn+7YsUOzs7M1ISFBa9eurYGBgerp6akDBw40+v/VbPP4+HjjotM6nxMnTmjnzp21UaNGunr1alV17JhU1L6RnZ2tp0+f1tDQUH322WeNtv/884/Wr19fn3rqqXx9w5E6jh07prVr1zYuSP/99189e/asNmzYUCMjI7VJkyZ65MgRo/2ZM2e0Tp06Ntvlscce09jYWI2NjdW7775bv/76a83Kyiry9s7OztbHH39c77//fpt99sEHH9R27dppt27ddOjQoTZ1WG3cuFHLlCmjqqpjx45Vi8WiU6dO1T59+ujIkSN13759WqFCBR0+fLjxnDfffNO4UMz7hqeo687RmnNycvSNN97Q9u3b6+LFi3X06NFaqVIlmzeu1r7lSM3Z2dnap08fDQwM1J9//llzcnK0ffv2Wrt2bY2IiFAPDw+9++679cCBAzbLWZT91pGaHd0PrYq6b02YMEGbNm1q89yvv/5aq1evrj179tQtW7aoqmpycrIGBQXZjJ7Ytm2bVqpUSd955x1jW+Refy+//LL26dPH5g1fv379tGHDhtq0aVPt16+f/vbbbw6tO6tXXnlFGzZsqKqqLVq00CZNmuiTTz6p9erV0/r16+urr75q1OPoMb0o6+7w4cNapUoVmzd606dP16pVq+YLhh3Z3o6ui8zMTK1UqZJ6e3vrpUuXNDs7Wzt16qR16tRRb29vLVOmjDFCIjMzU0eNGqWdO3e2CYIXLFigJUqUyLcejh49qjVr1rR5k2G95ly1apVNW0f7x9y5c7VHjx66atUqXbZsmYaEhNgEU9ZzxtWsO9WibUNH1oej54r9+/dr5cqVbY41s2fP1h49eujFixf13LlzxvScnJwiX6c4ug2Lel7JvW2Kum8VtX84snxWRb1OcWR9OLLPZmRkaN++fbVnz542td1zzz3as2dPffrpp/Xtt99We3788Udt1aqVHj9+XDt37qx+fn66d+9eHTdunP7www8OXf/ndaXzsnU5q1evbrMN+vTpo3FxcdqwYUPt3bu3/vHHH1d1bnHkWFrU94dXs66Len67mrqL0taRfnc112E7d+7UunXrGuFrVlaW7tu3TytXrqyenp7aoUOHfPvMlfIAR/dDR+su6jWvo8ewq0Uo9R8999xzxg6cu2NMnTpVvb299YMPPlBV25O1NfW0DuEcPny4Ojs7GwcZ1csdqHfv3jbPVVV99dVX1dXVVRcsWGDzmCPtHa05IyND27ZtqwcOHNBFixZpSEiI3nvvvdq/f3997rnnjA56/vx5LV26tM2Fh/VNi/UTBuuwcKt33nlHO3furIsWLdI2bdoYn9ScO3dOO3bsqM2aNdN///3XoXk70jYnJ0cvXryodevWtRkabd2Zjx8/roGBgfrEE0/opEmT1GKx6Jw5c/Ts2bParFkzjYuL03Llymm1atU0ODjY+Ord77//rvHx8bpixQpdsWKFdunSRWvVqmUETXlPXGvWrClye0dq/vfff/Xtt9/Wjz/+2Hiu6uWvwkRFRdl8GpqUlKQPPvigLlq0SPfs2aN9+vTRgIAA/fXXX+3WnJOTozk5Ofr0009rr169dNmyZRofH69nzpxR1cuBR9WqVbV9+/aanZ2taWlpWq9ePW3fvr1OmzZNhw0bpp6envrRRx/pr7/+qk899ZQ2aNBAV6xYoSdPntQ5c+ao6uULnc8++0xDQ0O1f//+xutnZWVpdnZ2kddF7mUoSr+zXoAWtY86Uoeq6tKlS20+ucjJydH09HSNiYkxgjwrR/r03r17tU6dOtq6dWutWbOmxsfH64YNG3THjh06b948m0/6rNt88eLFV9zm2dnZmp6erl27dtUuXbrkq+PkyZNapUoV7d69u6o6dkw6d+6c1q9fv0h948KFC3Y/cXr66af1jjvuMN5MW/u6I3UcPHhQvby89NNPPzXaHTp0SBs3bqyLFi1Sf39/4w1LTk6Opqamanh4uPbs2VOXL1+uI0eOVE9PT50wYYLOmTNH27Vrp3feeafu3bvXoe2dnJxshIOqqq+//rpaLBYdOHCgvvzyyxoQEGATFuXePo0bNzY+LJg8ebJaLBb19fXV33//XWfNmqX33Xefnjhxwnjec889p3fccYc2bNhQa9WqpYsXLzbm58i6c7Tm48eP6/Tp01VVNSUlxXjjmvvrCtnZ2Q7XfPjwYe3evbs2adJEK1SooG3bttXt27drcnKy8Yn7ww8/rKqXjyGO7LdFrVnVsf0wJydHMzIyirxvTZgwQWvWrKnnzp2z2S6zZ8/WChUq6IgRIzQ7O1sPHTpkd6Roly5dtF69esbfud/cnjp1yubNgXU7Dh06VD/44AO94447tHHjxpqamlrkdWet8fvvv9fWrVvrd999p61btzbe4KSnp+vTTz+tDRs21EOHDjm0TRxZd19//bVxLWOt6eLFixoREaFz587Nt56Kur0dOSdbbdu2TYODg7Vjx47auHFjbdOmja5atUp/++03fffdd9XZ2VknTJig2dnZ+vXXX+u7775rU9vJkyc1MjIy3wcY8+fP1+bNm+uuXbtstmtsbKxxbWd1+PBhh/rHmTNndOHChcZ0azCV+4NKa1tH9hVHtmFOTk6R18e5c+fyjXxWLfhc8csvv2jXrl1tvgY7bNgwDQ0N1Ro1amhkZKR+8MEHxnYt6nWKIzWrqkPnFasffvjhivvW4cOHHeofRV0+63+Lep1S1D5tXW9t27bV/fv3F2mf3bZtm83x67XXXlOLxaIPPvigDhgwQF1cXIyvb+a2bt06rV+/vnE90rNnT3VxcVE/Pz9NTk526Po/7/X6lc7Lqpf3Fy8vLx02bJj+/fff+tJLL6mHh4eOHDlSP/roI61YsaK2aNFCz58/X+Rzy9Uclxx5f1jUde3ItWPu0bJFqTszM7PIy+jofpicnGxcC6te+ZomKSlJ3dzcbPrlnj17tF27dvrjjz+ql5eXvvPOOw7nAY7sh9a6i3otVtRr3oyMDIfWnXX5HEUo9R+999576uvra5zEcieTL7/8svr4+BgHotwHqsaNGxvD7B9++GH19fW16cwvvPCChoWFaWpqqqqqzaf5jz76qEZGRtqMchkxYkSR2ztSs+rlIYg1atQwatu0aZN6e3urxWIxPpG1Lttbb72lEREROn/+fOP51lpeffVVbdCggf7zzz9GZ92+fbu6u7trtWrVtEuXLjY71sGDB9XZ2dm4CHr77beLPO+itrXW/d1336m7u7t+8cUXRnvrJ/BffPGFRkdH68GDB3XEiBHq7Oys5cuX1y5duujff/+tFy5c0D179minTp20bNmyRmiR+2sUy5Yt07vvvltr1aplJNI5OTk2fcL6lb2itp8zZ06BNU+bNs2oef/+/cbjuS8Yy5cvb7OdN27caGxP1cufbvXu3VsDAgJ0yZIlxvOzsrJs+tfvv/+urq6uWq9ePe3Zs6fRRvXyMHE3NzcjXNu+fbvWrVtXH3jgAY2OjrYZ5nv27FkNCgrS1157TfM6d+6c8QlB7gPxl19+qQcPHtTZs2cXuv2ioqL04MGDNqFcQf0uKSnJpt8V1vbo0aM2ba9UR0REhG7atMlmHeXeLqqq5cqVszkRLlmyRLOzsx3q/3v37tUqVaronXfeabONVS/vR9HR0cbojytt82PHjmlycrLxWn/++adaLBabT8EuXbqkqqorV65UHx8f3bJlyxWPSeHh4TYXxtZPmYrSN/KGZaqX30yXLFlSR48ebbO8V6ojIiLCODbm5OTokCFDNCIiQp9//nn98MMPNTAw0Ohzb7zxhrZu3VovXrxo1L1q1SrjqyxBQUH65ZdfGvP/559/1M3NTT/++GObC7yibG+r3bt3a9euXfWXX34xpq1bt05FRH/++WfNq3Xr1sYFzIABA9Tf318tFou+8847evr0aeNCR1V14sSJ6urqqu+8845+/fXX+uijj6qXl5dx3yhHziu5FVbzH3/8ka+96uV+Zu+N63fffWfzdabCarbuU0eOHNGOHTtqq1atdM+ePTav8/3336u3t7du377d2A5FPf7nvcjKW7N1P5g7d65mZ2fr33//XaT90Lq9i7pvzZo1Sz09PXXjxo2qansO/+CDD9TNzc14g5Rb7uNySEhIvvui5P3g4dixYzpo0CCbIGLTpk1qsViMvlfYups+fbrNutu/f78GBARouXLltEWLFjb9ybqvWEeeFnZ+s7dN/vjjjyuuu08//dTm4jsrK0svXbqk5cqVs3sfFHvrw14ftX49ytF+tG3bNvX29taaNWvajFC/dOmSDh48WBs1aqSnT5/WkydPGo/l/rp4TEyMJiYmGo/98ccfun37dptjkPW406BBA7v3FMm9jPb6x/Hjx/XkyZN232Dk5OTo8uXLjWDK+lpTp07Nt58XtO7mzp1rvG5R+3/ugNre+rCu87w1XOlcoao2x4spU6aoi4uLTp06VVeuXKljx45VFxcXXbNmTb7nqRZ+nWLdVwuq2cpa85XOK66urjbr6eDBg0Xat7Zt22bTP/P2j9zrNvc6K2j5zpw5Y1yHqRb9Oj33eaOw9TFp0iSH9tnc11WJiYkaFxdnfHiiqvrtt9+qj4+P3QApLi7OWP5u3bqpt7e3ent766ZNm1RVHbr+z6uw87J19PQXX3yhbm5u2r59e/Xy8rL5KtfRo0fVYrHoDz/8oKqX+2lRr/EcOZZe6f2ht7d3vtcraF1/9NFH6u3tbazrK+3fXl5eOmrUKOM1Czuevv/++zZ1F/XYm5KSYjxelP3QqqBrGovFYrQ9ffq0Pvzww9qkSROdMGGCzps3TwMDA3XgwIGqqtq3b1/t27dvvnV3pTwgL3v74YkTJ2z2w8Lq/u2334y6r3TNO3LkSI2Pj9eLFy/a9G1H1p0jCKWugnWEiOrlDdK8eXNt2LChcZC17gjWG57lHgps3dkSEhJ03rx5+tRTT2mpUqU0MTFRhwwZohaLRefOnau7du3Shg0b6gMPPGAcsKwH9vXr12t4eLjNJ1y7du3SuLi4AtuXLl3aSOQLq3n9+vUaFhZmfI/UupyPP/64cUB94IEHNCgoSEuUKKFNmjTR6dOnGye2rVu36n333adNmjTRRYsW2ay38ePHa3R0dL6bub3//vvq5+encXFxxsXXzp07ddCgQVqtWjXjZL59+3a78z516pS+9NJLGh0dbYza2rJlS4F1TJkyRStXrmwzFPuff/7Rp556SsuWLaszZswwpqelpek333yjd9xxh7GuRo8enW8nVL18YRocHGwEMHktX77cCJqsbYYOHZpvyKq99vPmzdPZs2drixYtjPuinDp1ym7NO3fu1C5dumh0dLTdE7+1TVBQkK5evVpXrlypI0eO1ICAAD116lS+71RbQ4pff/1Vjxw5ot27d9dHH33U6F/nzp3TIUOGqJ+fn82nILt379ZHH31UAwIC9M033zRGZV24cEEzMzO1SZMmxoFy//79On/+fK1SpYq+9957xn6S+4IhLS1Np02bpkFBQRoXF6d16tRREdFdu3bpmTNn7K4L1csXNb6+vsbJ3Mpev9u0aZNGR0drpUqVdOPGjcbr22t76NAhnTFjhsbExOjy5cs1PT1d09PTddCgQRoTE5OvjokTJ6qLi4uOGTPGpu9ZZWZm6vnz5zUqKkp//vln3bFjh/bu3VstFosePXq0wD6dnJysw4YN04iICJthtUePHtWZM2fm+6rvxIkTtXr16vrvv//mqyHvNv/oo480Ojpamzdvrp9++qmxPl5//XV1dXXV999/33jewYMHdcaMGXrHHXfogQMHdPfu3QUek7755ht1dnbWJ598Us+dO2dcSF64cEEzMjJs+kZWVpYeOHBA69WrZwz9VrXtz9ZPIwcMGKAtW7bU1NRUmwCyoDpmz56tXl5eOmnSJGNe27dv19dee02joqK0YcOGNm+g+vXrp8HBwflGF5w7d07PnDmj9evX182bN6vq5SDt1KlTGhcXp/Pmzcu3nnNv7/nz5+u6dev0nnvuMbZ37r6f+02p6uWLPVdXVx05cqTRl6zL1L9/f/3kk0/06aef1lKlSum6det0+PDharFYdNKkScZ6OX/+vD799NM2y3L69GktVaqUcePKwtbd/PnzNTg4WEeNGqWnT5/OdyPUvDVPnTpVvby88h2Pczt69KiOHj1aK1SooC+88IIOHjzYWB8F1Xzs2DGbmq19KSUlRefNm5ev/48fP179/Pz0xx9/tKnV3vHjyJEjOmrUKA0NDTVCg7xfO7LWHBMTo9WrV9du3brZ1FzQfjh+/Hib/dC6vceNG5dv31K9HP5XqFDB+Ophly5dNDIy0rjItl7cHzlyRMPDw/XBBx80zst5w5V//vlH4+Pj9b777rMJWO3JfVPev/76SyMjI7V8+fJGUFjQuXP37t3avXt39fPz08mTJxvr76effjLunWg9hyYnJ+uKFSu0SpUqxrYtaJuoXu7/pUuX1nfffVeTk5ONGq2hgb11d8cdd+i+ffuMabnXScOGDfWbb77RU6dO6Y4dO3TYsGHG9sv7dQvr9q5YsaKOHj1an376aWN7F7QuVFU//vhjLV26tL7//vs28zx48KBOmzbNpn8cOnRIe/TooTExMXrixAlj37L2PestAkJCQnTr1q36999/60MPPaQWi0VTUlKM7Zl7GePj43XChAl65MgRXbx4sd57773GSJuC+kd8fLxGR0frhAkTjONM3r6SnZ2ty5cv18DAQK1QoYI++OCDarFY9O+//87X1rruKlWqpCNGjLDZvwvr/8nJyfrJJ59oeHi4zVdvcy+ndX3Mnz9fH3roIaOOlJQUuyNXrOeKxMREXbFiheb177//6oQJE2y+TpWcnKzh4eF6//332yx/btbrFOvX1Tp37qwWi8V4s2iv5hUrVtgc/63b0N55JT09XVetWqXu7u7at29fm9GS9vYt1cvnp2bNmumyZcvyfV3XKj4+Xp955hktX768rl69WsePH5/va865ly80NFS7du2qpUuXVhExlm/nzp12r1MOHjyo/fv315CQEJvgz976WLJkiW7fvl1HjBihImKsD3v7rLU/9+7dO986VtV8P/4wZcoUjY6OttkPMzIyNCMjQ+vVq6e//fabPv7441qqVCn9+uuvtWPHjmqxWIzR2QVd/y9atMju9b91nx0wYIDNefmvv/7SgQMHqojoO++8Y9R88uRJ3b9/v9arV8/4StTevXv1888/18jISP3pp5+M67xDhw7pN998Y3PsSE5O1meeeUajo6ONc0thx9IpU6bYfDBX2PvD1atXq6+vr3Gbmbxyr+ukpCQtWbKkhoWF2QTx9q4dVVU///xztVgsGhoaanN7CXt1b9q0SUuVKmXzoVhBx97k5GR94403NDw83O77obz9bvbs2dqqVSubfmeV95pm5syZGh0drW+99ZZR87Jly3TQoEEaHByssbGxxr3sNm3apH5+flq3bl3j+dbn5M0Dli5dqg8//LCKiBFMFXScse6HJUqUsNkPc8td986dO7VVq1YaExNjhIsFXfNu2rRJS5QooVWqVLF7jZD3PKR6ObjNex5yBKGUAwp6g79gwQKNi4vTu+66y0gSk5KStEqVKurm5qaenp5at25dmzeBb7zxhrq7uxtDUEeOHGn8stCOHTs0KytL33//fW3QoIE+8sgjxleiVC8nym5ubjps2DDj4JSdna2TJ0/O1/7UqVN6+PBhLVeunM0N8OzVvHHjRg0ODtbw8HCbTzlUL3/CMXjwYO3Zs6fx6wqRkZEqIuri4qI1a9Y0DvBLly7VTp06ab169fSbb75R1cs3myxZsqR6eXmpj4+Pzfo4cuSIjhkzRt3c3LR37976559/as2aNVVE1M/Pz/glDFXVX3/91WbeSUlJWq9ePQ0MDFRXV1dt2bJlvrb169c36ti4caNGRkZqgwYNNC0tzWZH37p1qw4YMEDDwsL0vffe06SkJK1ataomJCRozZo19fTp00bb9evX27yZ2LVrl5YrV07DwsKMT1Xs9ZXly5drly5dtGrVqlqpUiUVkXyf1uVt37JlS3Vzc9OgoCAVEQ0PDzcCnqSkJKPmd999V0+fPm2ENcHBwZqUlGR3vrt27dKAgAANCwvTOnXqqIeHh83ILnvBVGBgoHp7e6uIqKenp9aqVcsmjOzXr59aLBYdMWKErlixQgMDA7Vq1arq6emplSpVMt4EZmdn64ULF7R69eo6YsQI3bx5s4aGhmpoaKhaLBYNDw/XV1991eb+S9Z6/vzzT/Xz81MRUScnJy1VqpRxsWZdF6Ghofree+/pxYsX9cyZM1qxYkUVEb3//vttviZl7Xeurq7ap08fnTVrlrq7u2ujRo20XLlyNifYw4cP68svv2y0/fbbbzUkJERDQkLUyclJw8PDdezYsXrq1Ck9evSo9uvXz6aOTZs2qaenZ74LstzrOzMzUy9cuKClSpXSqlWranBwsFosFuM+Ear5+3RSUpJWq1ZNg4KC1NnZWWvVqmX3hxCs9u3bp40bN9Y77rjD5hOlvHbv3q1dunRRi8WiZcuWVREx1rPq5fDC+qnhCy+8oD/++KMGBwdr165dtWLFinrixAnNzs62ewyz9j1/f3+bYMDq3LlzRt9QvfzV1tDQUHVxcVFvb2+bY0fek97s2bPVyclJe/XqZXylKysrSydNmpSvjoyMDG3fvr2KiLZt2zZfOGwNlawyMjI0OjpaRUR79uxpc1+dnJwcPXv2rEZEROiUKVN069at2qBBA+3Tp48xSi+vrKwsY3tXqFBBQ0JCVES0cuXKxvJZ96+8+66np6dGRkba7UufffaZWiwWLV26tH711VdasmRJnT17tr733ntGkGCdX+4bhR88eFDfeOMNjYiI0DfeeKPQdbd582YNCQlRNzc34x44ufdZVduLqMTERHVyctIyZcrYHEdzt7PWtHr1ag0NDVUR0RIlShjHJXs1b926VWvVqqUVK1a0Ga5e0P3QMjIytEKFCioi+sADD9hsw82bN9scP9avX68VKlTQsLAwdXJy0ho1auQLlqw1HTx4UCtXrqwiom5ubjaf7NuzdetWDQsL0+bNm+cLh1NSUnTUqFHq4uKiL7zwgq5du1b37t2rI0aM0IoVKxrhztatW7VRo0YaExNjrPekpCStUKGCenp6qru7u9aqVStfzVZz585VEdEqVarYfVOedxkTExPV3d1dGzZsaBPOWx/r37+/zboLDAzUypUrq5eXl1auXNnY1//991+dPn26enp6art27XTSpElasWJF43hXrVo1Y51Yt4n1nHzx4kX9888/1cfHR318fLRUqVJatmxZHTp0qB4/flwzMzNtjkurV6/Wd999V1u1aqURERHGKIi8/aNevXr62muvaf369Y3zbOPGjfOtA+t/ly1bplFRUSoiGhAQYHONkvc6wlqz9X4v3t7eWrt27QK3i/VXk6zXNHn3Leub8+TkZA0NDdVffvlFfX191cXFxWZEW95jY6tWrXTw4MF6xx13aFhYmIqIVqpUqcA6Jk+erCKi9913X743Y9b5W//9+++/xnnW3d1df/rppwLX3bFjx/Sxxx5TEVEfH598N+bP2/9//vlnrVKlitE/atasme/4b10fISEh2q5dO7VYLOri4mIz2jbvNl+1apU6OztrQECA9uvXz+4IirwjqK33hvHw8Cj0PPTnn39qRESEioiKiMbGxhZYc2BgoFaqVMnm+G89h1vPK5GRkUbovmXLFvXy8lI/P79815pZWVn62WefGfvW/PnzdenSpdq6dWv18fGxCQLy1tygQQN1cXHRIUOG6MiRI9VisRjn/LzH6HPnzulLL72kIpLv2lFVdfHixfmu06Ojo7V06dLq4uKi0dHR+W6kn3t9BAUF6f33368+Pj4F/uiPdZ/N3Z9jY2ON/mzddrmfZ/3BDH9/f7v74bPPPqtBQUEaGRmp33zzjZYsWVI//vhj7du3r83Xk/Je/6teHo3j4eGR77rK+vrW0KV06dI6c+ZMveOOO7R27drq5uamlStXtqnj+PHjGhYWpt99951xPAgNDVUnJyctXbq0vvrqq0ZgmLePVq9eXQMDA9XFxUVr1apVpGNpUFCQzY3/f/rpJ23YsKHx/tC6j9euXVtFRNu1a2czWirvdcquXbs0KChI69atq23atLH5YCPvtePff/+ty5cvV1dXV/Xz89OyZcvq2LFjjfZ5j6dr1641zkO1a9e2uZ6wdx6yXks7OTnZrA97+2FERISWKVMm3/usvP3fuq4DAwPV19dXvb29tUaNGsa2SE9P1xMnThjryHruzHu/Oqtx48apm5ubRkRE6MyZM7V69eoaGxurbm5uWrVq1QKPM1faD/Nul4yMDO3WrZuKiIaFheUbaZ/7mtdac/Xq1fWxxx6z6WfW9ZH7PHTgwAEdO3aszT57NQilimjbtm3q7OysgwYNMqbl/tTq22+/1bi4OI2JidHPPvtMAwICtFGjRhocHKzLly/XSpUqGfexUL2cqt9333367bffaqlSpTQhIUE7d+6szs7ORgqdmZmpb7zxhjZo0ECbNm2q27Zt0y1btmijRo1URDQ0NFS//PJL4wSWkZGhb7zxhtavX1+bNm2q8+bNU2dnZ61bt66WKVNGjx49WmDNU6ZMUQ8PD23QoIGRbOc2a9Ys9fDw0AoVKuicOXM0ODhYX3zxRZ0zZ47++uuvGhwcbPMGc82aNfrYY4+pi4uLVqpUSV1dXdXDw0O/++473bVrl1aqVMn4xTbVy0OAv/rqKw0KCtKIiAgNCgpSb29v9fDw0Pvvv9/mu/OJiYn66KOPqrOzszo7O2t4eLj6+vrqlClTjAtUq99//10HDhyoLi4uWrlyZfXw8FAR0TJlytjcdNRqz549+uqrr6q7u7sGBAQY4ccrr7xS4K+eqKrxiY6rq6tOnTo1X9vcr/Hhhx+qk5OTuri4aPPmzdXZ2VmnTp1q09660+/cuVNLlChhcxESHh6un3/+udF2//79RqhXvnx5DQkJUQ8PD2Pd5f76ntW6detstk3eg1nemufPn69OTk7q4eGhv/zyi+7bt0+Dg4Ntwsv9+/cbvyDh5uamISEhWqpUKd24caM2b95cX331VVX9vwPkjBkz1MXFRd3d3bVUqVJaunRp/euvv/S5557TBg0aaM+ePY0Tb05Ojh47dkwrV66sNWvWVG9vb922bZvGxsbaXGgdPnzYZl3UqFFDvby8tHHjxlqpUiXt0KGDTTibnZ2tn3/+ufr7+xtBXlRUlG7YsEGPHDlic9H377//6hdffKElSpRQV1dX4yRmrblevXraq1cvPXHihJ48edKmjpIlS6q7u7sx+mrevHn65ptv6tKlS21+Knnnzp3q4uKiYWFh6uLiopMmTSqwTzs7O6uLi4uGh4ern5+fzp07VytVqqQPPfRQvm2pqvrzzz8bb15q1qypTk5Oxo0hrXKf9Pr06aNeXl4aGBioGzdu1Hnz5ukbb7yhy5YtM96kfPbZZ+rj46MWi0UDAgI0PDzc5n5P1mNS7mNY7969tUqVKsY+mHtdWPfJGTNmGG/IrBcrc+bMMY4d9pZx8+bNGhUVpSVKlFAfHx91dXXVzz77zKhj/PjxGhcXZ3MsbdasmXp4eGj58uXz9Q1r/1C9fPwfPny4uru7a9OmTY2+lPfGwWPHjjX2E4vFok5OToUGFLt371YXFxctVaqUurq66pw5cwrdhvv27dOGDRuqq6urbt68OV9fSklJ0aNHj+qTTz6ps2bNKvQno3MvX1JSkkZFRWlERIS6u7urq6urTps2ze66++OPP7Ry5coaFxenpUuX1sOHD9vdZ60WLlxo7OebN2/WnJwc/eeff2xGraj+X9+zHkstFouOGzfO5lhqDW9VL/+aYcWKFdXZ2VldXV3zjYTMa9u2bTpixIh82zB3IJOcnGyEz05OThoSEqKBgYHGqLDcb7Zz16yqWqNGDXVxcdGyZcva7RtWq1evNoKPkJAQuyNlU1NT9fPPP1dfX1/jzXtYWFi+e6mtW7dOmzdvriVKlNCXX35ZfX199c4779QSJUroihUr7NZsDfmtX0u2vtEpaMSudd25u7trkyZN1NfXVxMTE/XIkSM2X0k6ePCgvvLKK+rq6moc/0uWLJnv+G+1dOlSjYmJUScnJw0ICNCoqCj94Ycf8l0b5D4nR0dHq4eHh3p5eRn1WkcqdenSxbhumTZtmvr4+Kizs7N6enqqi4uLuri42Jw3resiPT1do6Oj1c/PT1u2bGl8il+2bFm7byD279+v5cuXN64NrGFoQdcRZcqUUWdnZ/Xy8tIFCxYY586820X18hu2atWqaVxcnAYEBOiWLVsK3LcuXryolSpVUjc3N3VycrIJxnKzjrKqWbOm+vj4aJs2bdTNzc34IKGg/vH0009riRIldNCgQZqenm73nJX7zUnNmjXVxcWlwOsOa9sDBw4YHyyFhoZesf87OTlpYGCglixZUr///vsCj48XL17UGjVqaPny5dVisWh0dLTd/dB6j6d9+/apm5ubli1bVtPT0+1+qm/dprt379bQ0FDjA6uVK1cWWIe1bfXq1Y1tXlDbLVu2GMcMe8f/3KPHrNfykZGRxld3rcf/8ePH69KlS43AeunSpVqxYkXjwxwvLy+tUaOG3XN+VlaWbtu2TS0Wi3bo0EHfffdddXNz019++SXfaCDrOtq6datx3N22bZtxTM99nW59D2C9TildurT6+/vrxo0bNTw83O6HYn/++ac6OTlpVFSUurm52X1zm5WVZbPPtmrVqtD+bLVq1Sr18vJSd3d3XbRokd398KuvvtImTZrozJkz1dvb27ipub2b8ud24MABDQwMVIvFoqVKlbLbpxMTE3Xw4ME6d+5cDQ4O1hEjRujBgwft1pGZmamPP/64EXqUK1dOS5YsqRs2bCjweLB7924NDg7WO++8U319fXX+/PmFHkujoqLUxcVFPT09851XsrOz9YcfftD69etrTEyMLlq0SJctW6aNGjUyQtmC3luoqg4cOFCrVKmiJUqU0MTExAKvHf39/Y0Po318fHTDhg3ao0cPbd26tc3Ia2vdrq6uxmgq6/oo7Dzk7OysISEhGhAQYJxbCrp2zL0frlu3rsA+qnr5FgvWvrRw4UJjG9r7kNV67mzatKkGBATotm3b9MiRIzb71ooVK/Tee+/VuXPnamhoqL7wwgu6ffv2Qq93rfN2dnZWNzc3Yz/MO+/c9u3bp82aNVMXFxeNiYkp8JrXWnPjxo3Vz89Pt2zZUuB8rcfd+Pj4AvdZRxBKFcHRo0e1fv36WrduXfXx8bH5CknuND4xMVHvu+8+dXd3V39/f42NjTV29rfeeksbNWpkM99NmzZpmTJldPjw4cbJp3///vriiy/afFIzf/58veuuu9TNzU0rVaqkYWFh2q9fPx06dKi6ubnZfH1O9fLNGps0aaIWi8V4c3TfffcVWHOHDh1URDQwMFCrVKmia9eu1RUrVugPP/xgnNDT09P1hRde0FWrVmn79u3zvdGJj4/Xjz/+WN98803jniXp6em6bNkyrVWrljZp0sS4T0lB60P18uiVpUuXardu3XTs2LHGztGzZ09NS0vTt956S1NSUjQ5OVnvuusurV+/vk6dOlX37Nmj2dnZ+uSTT+a7AfC5c+d0xYoV2qxZM61Zs6Z+8cUX2rRpU42KirIbTKle/trKc889p126dNHHHnvMWM/2Llw2b96sXbt2VQ8PD+3Tp0+BbbOzs3XPnj1GMGD9FMq6zfNKTU3Vhx9+WGvWrKkeHh7GqKdOnTrp66+/rs8//7wuXbrUuN/L1q1b9dNPP9V27drpmDFjbNbdhQsX9M033zROYuPGjTNGPK1bt07HjRunffv21RdffNHmqzFZWVl65swZjY6OVicnJ5v7D1m3+YQJE3THjh3GJz0//vijlipVSidMmGC8Xp8+fbRXr17aoUMHHT16tNFHfvjhB/X399dnnnnG5k3qpEmTNC4uTh9//HHjJPbbb79pmTJlNDw83AjR7rvvPv3f//6nDzzwgE6bNs34ZGP79u36ySef6MyZM/XFF1/UMWPG6P79+7VixYrapUsX3bZtmw4bNkx3796tqampWrduXQ0JCdHly5fr0aNHtUePHlqtWjX19vbWypUr63fffWd8WrFu3ToNDQ3VCRMm2Iymso4oefzxx41tsmPHDv3000+1Ro0axjZu1KiR3nnnnRoREaFVq1bVNm3a6M6dO/XcuXPauXNndXNzUxcXF01KSiqwT6ekpGj79u21Xr16OmXKFGPETEH71c8//6w+Pj7q6+trHJM+/fRTDQ0N1d27d+drn5OTo1FRUcY2z11zlSpVND4+Xnft2qU7duxQT09Pve+++3ThwoW6f/9+49ixfPlyow/NmzfPuHj09vbWwMBA3bBhQ4HrQvXyibpatWratGlTmxFB9pbR+lO1Q4cO1enTp+u6dev05Zdf1lq1ahm/MpKVlWXcDNbV1VUrVaqkgYGB+thjj9n0je3bt+vQoUONTw4vXLig//vf/7R69er63HPP5etL1vZ///23njlzRvv27atRUVH67LPPatu2bTU4ONjuRer58+f1/vvvVzc3N3V2djb274K24ebNm7Vv377q5eVl/FR43u3Stm1bPXTokO7YsUO9vLyMoeOZmZn5jum51114eLjWq1dP/f39ddmyZVdcd9YgLffFrL19duXKlern56fu7u5GwNunTx+tU6eOlipVSps2bWrcY83q2WefVXd3d+3du3eBx9KMjAx97rnntFy5curr66utWrUqcD2rXv76w7333qtly5a1uw2tx4N9+/ZpamqqNm3aVFu3bq0zZ840Lrytx7u3335bt2/fbvNJ+ccff6weHh46cODAQvvS+vXrtXbt2urp6anffvutdu/evcC6k5OTtW7dulqjRg319/fXDh062Pxyo9Xp06d10KBB6u3trQEBAdqgQQPjIr2gmjMyMnTChAlapUoVnT9/fqF1pKamau3atdXb21tjY2M1MTHR5vhYqVIl/f77743j/7x58zQsLExfe+01Y91Zj/8JCQk6evRo3bZtm164cEF79Oih99xzj65fv94YqVJQ/9+xY4cOHz5co6OjddWqVcY5e//+/Vq2bFmtW7eu9urVS0+fPq379u3TiIgIveeee/THH3/UzZs3G336+PHjNv0pLS1NQ0JC1N/fX728vHT9+vUFHncvXryoL774otaqVcsYaVHYdcS6deu0WrVq2q5dO5s3cHm3i/WDxTlz5qi3t7cGBQXZfCBib986fPiwEd5u3rxZMzIyCjyPnzlzRkNCQtTd3V29vb2NAKug/qGq2rZtW+3UqZPu3r270ON0VlaWEYAOGTKk0OuOjIwMveeee9TFxUVnzZpVaL+7cOGC3nPPPdq+fXtdsGCBsY4L6h+HDx9Wi8Wizs7O+vjjjxe6H6peHtlSr1493bt3b6Hr7sKFC9q+fXutWrWq+vv7G9vFXh0XLlzQXr16aZs2bbRMmTLGdUpBbe+55x7jw0zr9aC9tmfPntX58+frgAEDtGLFisZxPe/xv02bNsaInsTERC1Tpoz26tXLuC6yd85PTU3VO++8Uz09PbVEiRLq7e2tbdq0Mfbv2NhY/e6774w+eurUKS1VqpS6ubkZy5f7mN64cWPjzevx48e1bdu22rBhQ50yZYrxutZr2KFDh+qvv/6qJ0+eNK4lrKNNN2zYUOA568yZMxoYGGizz6oWvF8tWrRIIyMj840uy30Na+3PmzZtKvK5U/XyV5qbNGlihIqF9eljx44V+v7prbfeMu51eOTIEX399dfVy8tLH3jgAZv3T3mPBxcuXNCOHTtq+fLlNTIystA+qnr5WNqvXz+tX7++7t+/36b/Dx8+3PhGwc6dO7VHjx4aHBysd9xxhwYGBurQoUML3cfXrFmjERERGhAQoJs2bSrw2lH1/+5t1KNHD2P/Xr16tVosFuM2JVapqalaq1YtDQwMNM7LBZ2HLly4oHfffbc2a9ZMZ8yYYRx77a2Pc+fOGaOHXF1djb5rr4+qXg43IyIibI4F9rbhv//+q6mpqdqgQQP19vbWqKgo3bRpU773FtZb5fzzzz/aq1cvffTRR21C0IK2YWpqqvGhnHU/zD1v635r/TGHxMRE7du3rwYHBxd6nZKamqoNGzZUX19frV69er6a8x4PrMddNzc3m29TXC1CqSuw/krEPffcY/x6kaenp00wlffnGO+9914dOXKkzZDnX3/9VSMiIvTMmTN66dIlzczM1Oeee04feeQRm0+CrV/ha9u2rQ4bNszmQLR27VrdsWOHzpo1S2NjY1X18s1mPT09de7cufrII4/oBx98YNR811136YwZM/TDDz8ssOaMjAzt0qWL8WnwyZMntWPHjlqjRg0NDQ1VV1dXHTBggM3FSt6bWL7yyivq4uKiLVq00MqVK2vJkiX122+/NdbHo48+avNT73nXR+6fFbeGc7/88ov269dPVS9f2Fk/JS1VqpTu27dPz507p3369NGPPvrIZr6zZs3SatWqaXp6unGPDesF6MyZM40bBx44cECbNGlic0GZexSZ6uU03N56fvTRR42fS96+fbsOGzZMo6OjtWzZsoW2zczM1IcfflgDAwNt1l/ubT5ixAibNPr111/XcuXKGW/+xowZoy4uLtqtWzdt0KCBxsTE6Lhx4zQjI+OK66506dJG8NO/f38tU6aM7tixQ5s3b6533nmn3n///VqxYkVt1KiRMVRc9fJQ3KpVqxojJ+xt85CQEGPdrl27VsuVK6eTJ0/WkydP6muvvaaurq46atQo7d27t7Zq1Uo7dOigKSkpeujQIa1UqZLxiUTufenNN9/UypUrG9+pnj9/vpYsWVK//PJLvXTpko4fP15dXV31ySef1Hbt2mndunX1ySefNN64Wbf7hg0bjDcXW7Zs0djYWC1Tpoz6+PgY+9cbb7yhLVq00J49e2qdOnU0ISFBv/32W01MTNQuXbpomTJljBt/X6nmihUr5rtBYf/+/fXpp5/W1157Tdu0aaNHjhzR7Oxs/f777zU+Pl579+6tKSkp2q9fP+3Xr5/Nzajt9emsrCyH9qvRo0drvXr1bE4aSUlJGhERYXOMyb3NIyMj9f7777dbc5s2bbRnz57asWNHLVmypHEz/rzHjscee8zmjfTatWv1nnvu0UceeaTA+fbu3VvPnz9f5GNHZmamjhw5Ujt37mxznFq8eLGGhYXZjESz+vPPP3XHjh26aNEiu33D19fXZr38888/evz48SL1pSVLlhgXVDk5OdqtWze7F6mZmZn66KOPao8ePWy2t71tqHr5ImTlypV6//33F9iXWrdurT179tROnTppcHBwgdtl0KBBmpKSohkZGTpw4ECtWLGi1q5d2+gfha27efPmadmyZY2bJhe2z548eVK7du2q9erVM/pg27Zt9aOPPtIffvhB4+LiNCoqyiZ0/H/tnXlcldX2//cBAZnkcAAZFEQBmcwJQURQjFERzVAzUXNMu44pml5Nb6mZ073dspSytMzE0gZTbzmjNIiKMoXXscQplLICReGcz++Pc599z8M55znPgx7zfn/r/Xp9X99LbLbrWXvttdazn73X/vjjjxESEgLAvC+tqKjAyJEjERQUxHdfmdOzwPHjx/HTTz/JGkNLMc7b21tUhPb69evYsWOHRVu6ceMGli9fzm8wkpJ7586dGD58OI4dO4ajR49Co9FgyJAhJhemAP2Hhq+//pofsZSSub6+XradAvr6VzExMRg8eLBJ/+jv78/9o1z/f/XqVYvzu3Ftwe3bt8PT01NUjLmwsBAJCQmYPXs2AgICcODAAUX+4I8//oC3tzfs7e1Fx90N/a7hPBRyqgsXLsjKI5TY0uHDh+Hn54dVq1bxcRJoPLdqa2sRFxeHhIQEALAYx6OiomBvb88/LFmyDzkx686dO/y2sry8PIt5h6BX4TSAlN3du3dPdowD9B9BX3nlFWzbts3iPGxoaMD06dPRt29fi7q7fPkyYmNjERgYKLIPc7H22WefxaJFi0RXxZtrO27cOKSnp5v1/43r9Ol0OslxEeLn77//jldffRXp6en8AxlgPuYvX76clyKIiIgwmt9t2rTh8xsAxo8fj5iYGLM+3fBo+ZYtW0SF4RvnsMJxrSeeeAJeXl547rnnUFFRYTZmCboLCQkRfayVsucLFy5g4sSJvC6uqfaenp7Iy8vDoEGDZMVOAPxjhlBXSBgjKV/61ltvicpISL0/VVZWIjw83GJ+rNVqMXLkSEyYMEG0+C3lS6XsPzY2VvRuVV5ezmsjWprjFy9eREpKCkaPHi1po0KNOmE3OwB+idKgQYOQlZUlKrGi1Wot5ulCHFLy3gnoLyKYNGkSn4embPTVV18FoM8FZ86cyReTLNneihUrEB8fj6ysLJMyt27dmss8YcIEo52M5mQG9PXNevbsaVYfhvO2qqoKhw8fxs6dOy36xxUrViAhIQFDhgyx2G9tbS2WLVsm8mH3Ay1KSSAkFz/99JNoW96WLVuMFnn++OMPviJpmAgJL8YHDx5EcHCwaAX0yJEjoi8yS5YsgY2NDSZPnoyXXnqJF0o8f/68aHvi77//jl69evGVypkzZ8LW1hZqtZoX2bt06ZKouK4pmbVaLRoaGnDixAmkpaUhNTUVYWFhSE9PR1FREX766Sfs2rWL168ytUvo8OHDCAoKwo4dO7g8AwYMQJcuXfhimyV9XL16lW9pFByQsP1Y+Nu+ffvCxsYGffr04cctTBW8FBJJQ4RxMUSn0+H8+fN8x9Tly5dRWVmJ7777DkVFRaitrZXUs/BlpqGhAT/88APOnj1rsS2g34ZquE3X3Jgb6kxIKoqLixEeHo4vv/ySB6eRI0ciMDBQ9IzmdJeYmMgLT27YsAEDBw5EXl4ekpOT+bbva9eu4ZlnnkFycrKo6LlhYW5zY25YwG/UqFEIDg5GUlISnJycRPNn06ZNomNeQ4YMwWOPPcaf0zDw9unTBzExMQD09pqYmAhfX18kJSXBwcFBdKPEq6++Cn9/f6MtxcePH0dwcDB/mcvMzISdnR169+4tSpZyc3PRvn17pKamGhXHjI+PR0pKCv9ZSua+ffsiISFBlFAuW7YMnTp1QlZWFg9uAv/85z8RGBiIqqoq0VXlpmy6trYWd+7cQU1NjWw/c+XKFeTn52Pu3Lmif1er1SIwMJDvaGrMwoULLcq8f/9+i75j5syZinQREBDAE3q5z7hu3Tqj40G3bt2Cv78/T1pramqMkvxTp06ZtI3ExEQcOXJEUXtzx2fq6+v519OCggLU1tbijz/+wN69e0V1Ncw9X21tLS5evCgqFGpOfy+99BJat26Nb7/9lhcqNjcuwpHQvLw8zJw5U/Si31h3DQ0Noposluw/MTFR1H7mzJnw9vZGRkaG6JYxAIiMjMQzzzwDnU5/I+Vvv/1m0ZcKu04NZW6sZ0D/ovr111+Lbo0x5w/MjaElfyccd2qKbZiTu76+Hp988onRkXhhYcrwRdNUTSA5PlquHHv37kV1dTVee+01REREmPSPCQkJ/BpxQNr/b968Ga1atUJRUZHs+S3kBsKtW+np6di/fz++/vprODs7Y+HChQD0xY8nTpyIjz/+WFSXBDC26atXr/LirG+88QbOnz8vksPQ7169ehWlpaU8zhrWSWqcRwD6HVUnTpwwqu9nalwyMzMRFRXF21iaW7GxsTx2rl+/Hk8++aTZOJ6QkMCPZxw5coQfbzQlR79+/dC1a1f+b0n5mZdfftmocLC5vKNv3764cuWK0S4yASm7M7QzU/ZRW1uLu3fvcr3fu3dPch7u3LmT627Dhg2SuktOTsavv/4KnU6HS5cucR9iSg6tVov6+npcvnxZtGhsqe3t27dFNfIatwX0/v/ChQv8Z0vxs23btrh586bFmK/VakW+Y86cOWjXrp3Z+Z2Wlib6cCzl0yMiIkTlSgRM5bCTJk1CaGgoCgoKkJaWhpSUFLMxa+rUqSgpKYFOp0NeXh5fCDHn7zp27Mjnu+H7i6n2KSkpeOyxx/DDDz9YjJ3CsV6tVouKigqj529s01evXkVRURH27t0rqoFkTm5Df9C/f3906dLFpD9IT09Hr169AMjLlSorK/Gvf/0LWq3Wov3Hx8fzRTWhP3NzPDU1VVTy5ZVXXrGY45mqsynw1ltvwc3NDadPn+Z+X0AqT4+Li0NSUpIsfQj2b+g7APM2GhQUZPISK0u+VKvV4vXXXzcbOw3fLeSMoXDboyCv3L4FzOU/CQkJokVUqX4bx3tzdQmbAi1KmeHkyZPIyMgwuaDR0NCAvLw8vshTWlqKfv36Yf78+aLk0zApP3ToEIKCgnDz5k388MMPGDt2LBITE7kRX7x4EdnZ2aKX7O+//56fu585c6aoz+joaL5SOWHCBLi4uMDe3h6rV68Wfc0xJ3N1dTVKS0uxYsUKlJSUoKKiAj179kRKSorRS/3q1auh0WhEV2gLXL58mSdzwgSeNWsW1Go19u/fL5pkpvRRWVkJDw8PhISEoGvXrlwfV65cQf/+/QHotwa3bt0a//jHP3iBNkM9GSavn3zyCSIjIwHoX0KnTJmCtLQ0k0XaAP2xjl69esHX1xe+vr7o1KkTunXrxhMQKT0XFxeLXlpNtXVwcMD69etRVFRk9HXK1Jhv2bIFjDFERUVh3LhxvEA7oF+hF5yD4ExdXFzg5uYmqotiSndLly7lRasvXbqE7777Ds2bN0eXLl3w5JNPiuQ6ffo0GGP47LPPTH6VbzzmlZWVGDFiBEJCQkROu6ysDEeOHEFYWBhfQCwvL8eAAQPg6OiIzMxM7N69G1VVVejUqRP69Okj0ufly5f5UQZDZ3nkyBF88cUXiIqKws2bN7ndbd68Ga6urujevTsmTJiALVu2cHvt378/7ty5w/WxcuVKqNVqqNVqZGZm8q/Pn332GbZv385tpL6+HuXl5QgLC4O7uzvGjBkjKTOgv1FRo9HgwIEDIvsXjtSOGjWKO/GamhocOXIEoaGhosKRhjYq2HRpaSkyMjIwdOhQ9O3b1+iLPPDfeSW84Ofk5KB3796ilyPDAo9t27bFnj17UFlZia1bt2LRokWigtGmZK6ursa2bdv4/JXyHX/9619hZ2eHTz75RCSDqX6B/17X/Mknn1j0HYIvHTduHOLj40XFYQXd+vv748SJE1x3a9euFSU4dXV1GDRokMg2tmzZgpCQEGg0Gqxbt85i+zVr1sDf3x+RkZGia7sNfeW9e/cwePBgqNVqxMbGIjMzEyEhIaIvv6bGsLS0FO3atUOnTp1EL4Cm9FdWVgZvb29oNBpUVlbi2LFjZsdl7ty5sLOzw5kzZ4xqNjXWXXl5OUaOHImoqChZ9r98+XL06NHDqKD5qlWrsH37dtHR9OrqaqSkpCAtLc2iL7W3t8f06dPx0UcfiXaTmtKzp6cnNmzYgJCQEDg5OWHEiBGS/mDDhg2IiIhAfHy8UeIp5e8Mjy+as6WwsDBERERg2bJlFuX28PDAwYMHMXHiRISFhRnZh1Awe8iQIbh69Sqqq6uxevVqXtTfnMyAvlZXcHAwtm7dalEOd3d3LFy4ECkpKWjTpg2X4/3338eOHTtE/rGyshLp6emim3IB0/6/srISq1evhq+vLz788EPe1pz9V1ZWon///oiMjOS7C4Rivj4+PvD19eWLq8KNTM8884xFm758+TI8PDzQq1cv0RiayiWEtsHBwejZsydvY9hWyCPatGmDsrIyTJgwAV26dBFdUGNqXMrLy9G1a1e0aNECzzzzjKzY4uDgwI//SMXx/Px8MMYQFxdntCjaWI7S0lKEh4cjPDxcFPNN+ZnLly9DrVbD1dVV9IHNVN6xceNGODk5oXXr1oiLi8P48eNFOY3hjv3GdhcYGCjpH0tKSpCRkYGnnnpK5P+lfLqDgwOGDx9uUXeHDh0CYwwLFiwQzRVTcpSVlWHkyJHw9/eHr68vNm7caPR8ptr6+PhItjX0/507d7bo/wH98eCIiAjRhROAccx/5513MHLkSPTp0wdpaWnYvHkzANP5D6CvEdS7d2+jfNCUTy8vL0dAQAC8vLyMxrtxDltdXY2lS5ciNDQUv/32m2QusWTJEqhUKqSlpVm0ZwBYsGABmjVrhoEDB1psX1ZWBjc3N/j4+ODevXuSsXPNmjVwd3fHm2++ie3bt8vypS1atEBgYKDIl5qSw1QufePGDbRt29aozlJ5eTm6desGNzc3o3cFU7ZUVlYGV1dXfkuzHN/Rs2dP0Ud1U3N8yZIlsLW1Rc+ePUXHQuXkeIa5VWP9de/eHX379uV2OnbsWMk8vbS0FIGBgejatavF3FFqHja2UQD4+9//DltbW/Tv31+RLzX8eGQqdhq+W5jzjeb8geFJLEt9W3ofWrFiBVxdXdG5c2dRjSlT/QLAtGnT+OLfg4YWpUxw6tQpODo6iooLCzeeCNTX1/PbuhwcHNChQwfY2toarf4KRvDtt9/Cy8sLnTt3hpeXFxhjePbZZ0WJjZDEC//Whg0boFKp+MQxdGbDhw/H7t27MW3aNPj5+WHPnj2832bNmmHx4sWor68XTXJDmb28vHixVaGY3+nTp7Ft2zbRlxvBsJs3by5KJE3tmgL0iai9vT1CQ0ONCtk21oefnx/27dsHGxsb2NjYoF+/fjxBbGhoQHx8PLy8vODt7Y1jx47h4MGDvLji4MGDRcW5hbHZtWsXQkNDUV5ejrZt20KlUsHT01NS7p07d8LGxobXZzC8wUZKz3Z2dnj55Ze5A2zc9qeffkJ2djYvrG5vb4/FixebHfPy8nK4urrC3d0dCxYsQFpaGkJCQjBlyhTe3tC5Hzx4kBfjzc7ONqu7zZs3w8nJCb6+vrCxseEvDrm5ubzoteBUAX0hbbVajdDQUPj5+UnqTiiQ7OnpCUdHR/Tv31+0+FZUVIQOHTrgp59+QkVFBdzd3fkLRZ8+fdCuXTtMnz4d33zzDSIjI3lgu3PnDg4ePAiVSgUPDw+MGDGCb6cG9Ef5wsPD+c8VFRVo3rw5PD09sXjxYq67qVOnQqvVYtCgQXBwcICPjw8++eQTuLu7Y+DAgfD390fv3r3Rtm1bXqfHEEHmoKAgxMfHIy0tTVJmwf79/f1FRT8B/RGf2NhYuLi4YN26dfjmm2+QmprKt4UL26Ub63nXrl0IDAyEWq1Gly5d4ODgINrhZfg3wrwqLy9HUlISmjdvzvXW2BfU1NQgODgYH374Idq0acNvsElJSeFbca9fv464uDguc0FBAbp06QIvLy+oVCr+JdaU7ygrK4OjoyM0Go1R3arGuqiurkZZWRn3TcIOBnPPaMqXGn7Fra+v59d379ixg+uOMSbaXaPT6ZCYmAhnZ2f4+Pjg2LFjPHkzPJZorv2WLVvQpk0bREREoFmzZkhOTjYad4FTp07Bzs4OjDFRHQxzY3jq1Ck0b94ctra2ol2vpvSXn58PJycnuLm5oVmzZnwOCuNieAuLIIenp6fo5V3wS/fu3eO627VrF9zd3dGpUycwxizO2fLycrRq1QotWrTgvsPQ3xkm1aWlpejSpQvc3Nxga2uLxYsX8xfLxr7066+/5kW/3dzckJmZaVbP9fX1SEtL47FwxowZkv5g69atSE1NRWhoKOzs7PDPf/5TNB6GmPJ3ghw6nQ6PP/64yJZKSkrg6+sLJycneHl5ScpdXl6Ojh078sLm5gqGHj16lBeI1Wg0YIyJjo6YoqSkBC4uLvD09IS3t7ekHEVFRXBycuLxsHE9SMMxFPSh0Wjg5OSEzMxM0TZ+Q/8vtBUucUhLSzMpg2D/RUVFcHNzg0qlgkajEeka0Nu2cERIyNmCg4NFF2qYsumKigoeOxljGDp0qGQuIbQVdv2YW8Q6f/48oqOjeQF0Ly8vydgpxJb27dsjJiYGqampknPr1KlTvDCx4TFEc3H8888/h0qlQrdu3TBq1CijYsaC7GVlZVCr1QgLC8PQoUNFOzFM+WlBH66urhg2bJhkzlZRUQFXV1c0b94cCxcuNJnTCP+eKbszZx9eXl6ieGjop035dMGXCvFFSnclJSXw9/fntQ/NzRVBDsE/NmvWDLGxsUbP15S2Sv1/dXU1/v3vf6NPnz7o2LEjfxk2FfMDAgLQokULjBs3DklJSTw/NZX/AHq/5OvrCy8vL/j5+WHTpk1mfbpg04GBgfxjg7kcVvD/QoFwoeamqVwC0L8IM8aQmJgoac8C/fr1g0ql4se9zLU/deoUnJyc4OrqCkdHR/5x0FTsBIB58+bBzs4OXbt2tehL6+vr0bt3bzDGYGtri4yMDLNymIotQu0loU5T7969cebMGZw6dYr7jrCwMKSkpEja0vHjx3mRcA8Pjyb7jsZzPC8vD2q1mpcLMNxRcz85nk6nw7Rp02Bra4thw4Zh9erVSEtLM5unCz4sODgYo0ePhk6nE9l+49zR0jxsvPNn4MCBUKlUFm1PypcCEC3CmXq3aKo/kNu3qfxHGMOsrCx07NhR9HG8cb8C2dnZmDp1qpGeHwS0KNWI4uJiODs7Y/bs2aL/3viLFaAvPvjYY4/xa4GPHz+OiooKnDx50mhxatOmTbC1tUVUVBTs7OwwY8YMqFQqkQEYDq6QgAQEBODs2bOIjIzEkiVLuPGvXLmS3/SwdetWeHh4ICcnB6NHj8acOXOM+hYQklPGGFq0aMHlEL5kGi68lZeXw8PDA126dEF0dDSmTp0KOzs7o2toBX799Ve0a9cOzZs354mpOX0UFBSgU6dOeO6556BSqTB//nx07doV2dnZvK7JvHnzMGDAAJ4wVlVVYcCAAVizZg1vKzg2Qe7PP/8cHTt2hKOjI2xsbLBkyRLMnDnTrNxCMhsREcGdmlI9C7oT2goJmaC/bt264csvv8SqVavMjnldXR2ys7MRFRWF3r1745dffsGdO3fQpUsXqFQqPP300yK5b9++jVmzZsHe3h6LFi0yq7uPPvoIjo6OmDt3Lm7cuIGIiAgsXrwYWq0Wt27dwooVK2BjY4PRo0fj8OHDyM/Ph6OjI1q0aIE1a9ZI6u7HH39Eq1atEBcXBw8PD+Tm5sLHx0e000Cn06F9+/YIDQ1FUFAQQkNDeRHXO3fuoHPnzvz5SkpK+PntmJgY9O3bF7a2tnjxxReNxvvXX39FeHg44uPjMW/ePAQFBaF58+b8q5Wh7kaMGIH33nsPQ4YMQUFBAXeogt4N2wpfUYXfDRs2DNHR0WjZsiVOnz4tKXNUVBS8vLxERewF+xe+ttXU1ODxxx9HQEAAVCoVr2UzYsQIs3reunUr3Nzc+PXBJ06ckJxXwiIyYwxjxowxeZ23VqvFnTt3EBAQgJYtWyIhIQFOTk547bXXjMawscxt2rThxenN+Y6amhpeLDUrKwu1tbVmdRESEoKWLVvCw8NDVBD7fn1pVVUVfHx8kJCQgOjoaLi4uKCwsNBIjo0bNyI9PR3Hjx9HTU0NUlJS8Nxzz/FgbK79l19+iVatWuGFF15ATU0NL/DceKeNVqvl/UZERECj0aC8vFxyDDt06MALzQsJkJQtMcbQtm1bnoi8/PLLJq/EFuJbVFQUHxdAHN90Oh1u3LgBX19fDBw4kCeWhYWFkvb/2GOPwd7eHnZ2dli2bJmk7xB8Y2xsLDw9PTF37lyzvnTHjh1o1aoV5s6di2nTppn0M4b2V1tbi+DgYDg4OKC8vByAeX+Ql5cHDw8PzJgxA5s3b8b06dPvy98Z2pLQfu7cuaiursbu3bvNyn327Fm+wNS8eXN+jMkU5eXl/LZQZ2dnZGdnS8Zl4XIN4ZYlKTkEmTt37gx3d3esW7fOZFtBH35+foiLi4OXlxfefvtts/4/ODgYTk5OiIyMhEajwRtvvGG234KCAoSHh8PFxQU2NjYoKCgwKzOgt2knJyfExMTAw8ODL4Cbsmk/Pz9cuHABc+fOha2tLebNmyeZS8TGxnI/Z5ijNG4L6HMJe3t7ODg4YPny5ZL2X1dXh6effhrR0dHw9PRERUWF5NwSPnra2dnh0KFDiIyMlIzj169fx6xZs+Do6Ijly5eblVvwS1FRUVwOKT/t4+ODxMRE2NnZYcGCBZI5W11dHYYPH45p06bxxW9zOc2FCxdk293evXvh4uKCjh07GsVDUz5dyPH++te/4vLly5K6E27DjouLQ0BAADZt2mRWjgMHDkCtVqNz585cDnPPt2/fPtltDx8+rMj/h4SEwNPTk3/wGDt2rNmYf+vWLbi4uGDYsGF4+eWX4ezsjCNHjpjMfwD9QqGjoyMcHR2xcuVK2Tbt6+uLs2fPmn1GQ/+vVqsxe/Zss7mEwMSJE+Hr64s33nhDch7eu3cPCxYsgEajweOPP47c3Fyz7QXb6NmzJzQaDYKDg83GTkDv81xcXBAaGoqqqipJXwroFytGjRoFOzs7UZ7eWA45saWsrAwREREICgqCh4cH2rVrBxcXFxQXF0vaUvv27dGsWTPY2Nhg3759TfYdjef4kSNHkJqaikmTJgHQz+0HkeM1NDSgrq6OXwKwePFi3r8pO62pqUFycjK6du3K83RzuZWSOQvo37MEW+rTp4+kLUn50sY3Ept7t2iKP1Dat2H+k5+fLxrDuro6s/0KYzB//nzerzWgRSkDrl27Bh8fH6SlpQHQT44ZM2YgIyMDYWFh+Mc//iH6ClhbWwtvb284OTmhtLQUaWlpiI6OhqurK2JjY7F+/XoA+u2XwuKVh4cHTpw4AZ1Oh/T0dHz77bc4efKk6IVq586d/JpH4QauwYMHIzo6mrc5ePAgJkyYgAMHDqBXr16YNm0a/525vm/cuIGEhARERkbC1dWVH8dLT0/HN998w89NA/otjPHx8YiJiYFareYTMDExkb/QGzrsffv24YknnoC9vT0++ugjNDQ0mNUHoC86KizmCbUYPv30U0RHR2P8+PFISUlBXFwcX3lvaGhAVVUV2rdvj8rKSt52woQJiIuL49tP3377bTDG4ODgIPr6aUru4uJiODg4IDU1ld9g0BQ9f/PNNyguLsamTZswZ84cnDp1iut6+vTpFscF0G//DwwM5GMuJHFz5sxBVlYWunbtyov2ffXVV+jXrx9at24tqbu9e/fCwcGB3yIi2JFhXZGGhgZs3rwZfn5+8Pb2hrOzM1xdXUXHMMyN+YwZM+Dl5cXrgwD6r1O5ubl4//33+ZGS2tpaPPXUU3yB84cffhA935NPPomoqChe/PSNN97AnDlzkJOTg8DAQNHzTZgwAd27d8fTTz+N8vJy9O7dGz169EDLli0xefJkADDqu0ePHpg3bx5P1JKSkvC3v/0NwH/PcJvS865du/iVvEVFRRZlzsnJQUBAAD799FMj++/evTvWrVsHQD+3unbtioSEBGzYsIF/oTKn5w8//BCMMbi6uuLo0aOS8+qLL77g9v/CCy9ApVJh9uzZJpNUAPD394erqyvs7Oz4zgzDMRSOUN24cQMdOnRAr169uMzmfAegTzr9/f150mROF4I9r1y5EiEhIdixY4ek75DjS4WjC3V1dQgPD4darUazZs2MdNe9e3deQFQ4GlFXV4f4+HgUFRXxHTfm2ufm5iIxMVH0dc9Qd41vcAoJCQFjzOIYCr6xWbNm2Lx5s6QtFRcXw87ODsnJydiwYQPOnj1r5MOEpOnatWvw8vJCUFAQ1Go1iouLjeKbkGjU1dWhQ4cO0Gg03DdK2f+rr76Ktm3bIiYmRpSsmLJpYQzbtm0LHx8fFBUVSfrS3Nxc9O7dWzQnzOm5oaEB7733Ht89B5j3B2fOnEFqaqqRT2+Kv9u4cSM/XibYkqF9CP2YkrumpgZjxoxBz549+S4Rc3O2uroaycnJ6NChA1xdXfmim1RcFnaTGH7dNae/tWvXIiwsDIwxHj/NtZ0yZQrUajXf1dS4raH/79atGzQaDcaOHctvBzPXr6H9G8ZwU+2vXbsGT09PBAYGIiAgAMeOHbNo00lJSbCzs+O168zlEh999BHfmWeubVZWFgD9bahhYWFQqVSyYue+ffvg5eWFFi1aWIwtwgJafHw8r7EiFcd9fX0RFhZmMj9oLPfOnTvh4eGBli1b4tixYxb99OrVq3ndIks5G/DfWKvT6SRzmnXr1sm2u507d/JxKSwslPTRQo4n5EANDQ2SuhNucwsICDBp06bsVFjsNfV8QtHivXv3Km4rx/8D+sXT7t27Iz4+Hi+99JLFmO/i4gI/Pz/Y29vzxW9TY5KXlweNRgNnZ2dZNr1nzx54enrCxcXFyKYN+xb8v3CcrbH/b5xLnDt3DvPnz+dH4KTsec+ePcjKykKrVq2wf/9+tG/f3mx7IXaGhoaidevWJvN/w8Wu8+fPIyMjA82aNRPdQi0Vi9avX893oknJPX36dMnYctCg7ufrr7+ONm3aoHfv3nzBwZwt5ebmiuzufnxH4zlumCtZslElOR6gX1hMSkpCcnIyX7A3Z6eff/451Go1vLy8jHyYudxKah4avmdlZGQgICDAoi0B0r60sRw7d+6Eu7u7yXcLpf5ASd+N34ekxtBUv0lJSSIbtQa0KGXAtWvXMGjQIHTr1g2ff/450tPTkZSUhFmzZmHy5Mlo27Ytxo0bxx3mRx99BBsbG6xZswbPP/880tLSUFxcjH/961+YPXs2Pyp08+ZNLFy4EPHx8Xy1+eWXX4ZKpULnzp3RunVrpKWloaCgAOfPn0dycjI0Gg1OnjzJneLp06fh5uaGNWvWcHn/+OMP3Lx5E6+88oroeIypvo8cOYKbN29i9OjR8Pf35y+ghm39/f25HN9//z3UajV8fHxEcowZMwbZ2dkivQnFPnNycqDRaLBnzx5JfQD6oqOpqakoLi5GdnY2PzK3a9cueHh4wNnZmScXwH+DQ+O2np6ecHV15TfDff/993BxceE/S8ldWFiIF198ETt27BAdd1Gq506dOiEwMBADBgzA7t27AUD2uBQUFODcuXPIysqCo6MjMjIy+JbPy5cvo02bNnjvvfcwYsQI9OnTB4B+IWXVqlU4c+aMpO6E5zM8eio8n5DwCghFHMPDw/HZZ59Z1J1Op8PixYvh7u7Ob6EQzvwnJyfzVfp33nkHOp0OtbW1SEhIQHZ2ttnnE24REvo3N94uLi78DLhOp8Mvv/yC+Ph4jBw50mTf2dnZSEpKEslhrq2gZ+HLemBgIAYOHChL5uvXr8PLy0vS/rds2YLr168jJiaGXy8spWdAb9N2dnbIzc21OK+uXbuG8PBwLF++HIB+l5WpJFWo5yPsqBJuCjE3hpbs2dB3nDt3DmlpabCxscHatWsldaFEd0p8aX5+PqqqqsAYA2MM69atM+o3JycH3t7eoquHpeRo3H7dunVo164dD9CmdCf4oevXr8Pd3R0ffPCBLN+YmJgId3d3i7YkzHFDOxLmuOHNW4C+NoFwlfff//53s/Ht4sWLuHTpEl8g6d+/v0X7V2LTN27cwKxZszBhwgTRbTfmfKkSPet0OhQUFCA6OtqiP1AisyV/161bN3h5eeH999/nfyNX7tu3b+PNN9/EsmXLcPHiRbNzVtBzZGQkAgMDUVhYKCsu9+/fH/7+/rL0t27dOrRq1YrXCpJq+/rrr0Oj0Vj0/4a6EOpxSPV769YtREREoHXr1hZlFnK20NBQrF+/XtKmG19dbSmXOHfuHHr27ImSkhKLba9fv46QkBBem0dqXLRaLcrKyhAQECArtkjNcVNx/LvvvsOhQ4dw9epVi3IfPXoUTk5OePfdd2X5aXNxuXHOptPpUFNTIyvWKrW7M2fOwN7eXpZPV6q7OXPm8OPCUnLodDpcvXoV7u7ukv5RyCWuXbsmqy2gP4Eh1/8D4P4jLy8PgPmYL9QssrW1FS2empPjwoULaN26NT+CasmmhZv9BgwYIPmMN2/exEsvvYS5c+fyfEIqlxg4cCDatGmDkydPWrTn8+fPY9GiRTyuSLUvLCzElClTsGjRIr5Qbi52lpeXY+DAgfDw8JDllwSOHz/Oa8dKyW0ptrRs2RJvv/22ohwW0O8MateuHYqLi+/bdzSe43LzXQG5OZ7c9wVDO3V2dpb0YUK/cucsoJ9Xq1ev5kcoH4QvFeSQ826h1B/I7VvIf5SMCaD/uLR06VKr7ZASoEWpRly9ehWjRo2Co6MjUlJSRMUFN2/eDLVazZPla9eu4YknnsCUKVPQv39/US0ioWDdpEmTcPfuXfz+++/8nOqWLVugUqmwdetWVFdXIz8/H9HR0XjppZdw79490S0pgD7A37p1C0888QSGDh2Ku3fvir5Q/P777/x/m+tb2Bly7tw5fuOTJTk++OADvg1TkH3BggVGt2oIxeAbGhowbNgwWfow7HPUqFG8Ns24cePg7u6OiIgIjB071mhbrFRboa6AYeFBKbkN9Xa/ej5w4ABiYmK4nuWOi+GYb9u2DTY2NujVqxdGjhwJZ2dnjB8/HoD+/L2LiwsPnnL00Vh3jZ+vvr7e6FYtw0UHS2N+4cIFxMXFITg4GFlZWVCpVPj888+h0+nw888/Y9q0aUhMTMTPP/8MrVaLgoICyedzdXVFRUWFaOu01PMZXqsrp+/Tp0/zl1a5elYis06nk2X/9fX1Iscupec//vgDOp0OgwcPlj2vGhfXzcvLg0qlQk5ODvdn9fX1uHHjBjZu3IjOnTtbHMMbN26IijZasuf9+/cjMzNTli6E28vk+g45vnTRokUA9AUq+/bta7FfYfzkytHQ0IDz58/Lsv8bN24oej5Af/RIri0Zzt/Gc9xwft+9exfbtm3Dk08+KRnfhBfD1157DZs2bZJt/2fOnOH+UsqmhZtNhXluyZfK9TOGL2By/YGQcFqSWYm/E24tVSJ34wtVTM1ZrVaLS5cu4cyZM7wWoZy4fO7cOdlyyJW5qqpKkf+XK4NQN/Pf//63bDnk5GyGNi3sLpOTSwg6lGor1PdTEjsB/bEMpfFQ+P+W4riAlNyFhYXQ6XR46qmnFPsZuXmH3PipxJZ0Oh2GDh0q26cbYkl3SuQA9Av9lp5PsDclbZX6fzn+Q4j5q1evlp3/yLVp4Rh4fn6+rL6V5MYHDhzg7yGW7BmAbDtt3N5S7Dx48CAOHz6sOBbJkUNJrJCbSwu2ZFgf6UH5jqNHjyrKd5XkeII8cvN0pbmVpXlo6j1LzhjK8aUTJ07k46FkDOX4A6V9C7tulfT7MKBFKRNcuXIF8+bN47dQGQa24OBg5OTk8J+PHTsGZ2dnqFQq0bXHgP4WuoSEBKMJ/+OPPxoVSsvIyEBmZqakXNu3b4dKpZKsN2Gub+HGhKbIYSj//Pnz+fFGQH/15+rVq/mKrBJ9CHrduHEjFi1ahOeeew6+vr64cOECPv30UwQFBWHSpEm4c+eOrLYTJ04UFWVTIrch96Nnc2Mot31hYSFGjBiB8ePHi75kfPHFF6LbHJTorinPJ1d3Fy5c4Le2DR48WNTHq6++ik6dOolksObzye3bmm0t2X+vXr1E/sSSnletWoWGhoYm+RnDpFxI/GbPno0rV67g+eefx6BBg/h100rGEJBnz0p1YQ1fqtVqH7gchu2V6E7p8ymV2xCpOW4pvgn1FIWXYSX2D8izaUO/K8eWmmKjSuS2lr9T2t7SnH3iiSf4kWMl8U2JHH9mW8Nbk5T0rcSmleQSTYlDSsZF6dwyRGqOy33GO3fuKPIz1ozLSuzjfnyjJd0ptVNLz2f4kUhJ26Y8o9yYb02frrRvOf5fiT03pb0hlvJjJX5JiRwPOpdu/HFS7jMqmePWzK3kPKNgS0pzKyU2ai1fKkeO+/EHD0p3lnzpg4YWpczw22+/GRXKvHnzJnr06MG3aAscPnyYH3MwvFFg2rRpGD9+vOQqo1Bw+KmnnsLSpUslZbp79y5SU1ORnZ0tCooPom9LbQWjnD9/Pvr27QsAePHFF6FSqUQ7kwDl+sjPz4dKpYKPj4+ohsRnn31mdIOfkrZK5Rawpp7ltDflAHJycpCYmGh0Ja9SfQDyn0+J7t555x1kZGSI5szzzz+PgQMHGn3Fs+bzKenbWm2V2r9cPTfFzxge3czLy+M1FGxtbY2KlSoZQ0Ok7FmpzA/Klwo3cD0sOeTq7mHpw9Icl4pvmzZtMmqvxP4N2yvxu4Bl36jURpsyxx+0v1Pa3tycbdasmVEtB6V6ViLHo9BWSXulNv2o5B1K55aAnDguV25r5mxKn9FavtQQObqzVk5jzVxC6F9OzLemT2+qTVvy/0rtzpr5sRL7UCKHtexO6TNay3c0NT+29IzW6tfa+ngY7xaW+r4fX/qgoUUpBSxcuBAhISEmq9Ln5+fDz88PMTExGDduHEaOHAk3NzdRQTxzvPjiiwgICDC6Nt0Uy5YtQ4sWLfgRvAfZt1RbIcgtWrQIzz77LFauXGlUPNUQJfq4d+8e3n33XV4jRmpVVknbpsgtYE09K2lfUlKCv/zlL2jRooXJlwyl+hCQ83xKdCfcCLVixQp88MEHmDNnDtRqNUpKSv6U55PTtzXbKrF/JXpuip8RjqUBwOOPPw6NRmNyXJo6hoC0PSuV2Vq+1JpyKNHdw9KHUh8mFd8MkWP/TfW7gPQY3o+NWpLbmv5OaXu5c1apnpXI8Si0bUp7Q6Rs+lHMO5TEIcDyHFcit7VytsZYekZr+lJDLOnOWjmN0rbWjPlK5HhYNi3l/5XanTXzYyX2oUSOh2F3cp7RWr6jKe3lPqO1+gWsqw8lcjxqunvQ0KKUDLZs2YJnn30W7u7uklXnT58+jQULFiA5ORnPPfecxcH8+OOPMXnyZHh4eFisZi9MgF9++QVRUVH8jPWD6FtJW6EAn5ubGy+Wbg4l+jB1pvlBtBWQK7c19ay0fV1dHT799FMMGzaMO0JTKNGH0ucD5OvuwIEDCAoKQkhICBITEyVlBqzzfEr7tmZbpf5Arp6V9gvot/ULV5tLya10DOXas1KZreVLrSmHEt1ZUw6lc1xufAOU2T+gLF7IHUOlNqpUbmv5O6Xt5c5ZJTIrleNRaNuU9nJt+lHJOwBlNqpkjiuR21o5m4DcZ7SmL1WiO2vlNErbWjPmW9OnK+lbrv9XanfWzI+V2IcSOaxpd4+C72hKe7nPaK1+Aevqw5r+wFq6swa0KCWD4uJiZGRkiLa1SaHVamUZb1lZGYYOHWqyqJo5dDqd5FGapvStpO2xY8egUql4ATY5yNWHNVEqtzX03JT2dXV1suRQitznA5Tprrq6GtevX5c8z26ItZ5Pad/WagvIt3+lNqpkXgnXEzc+smcKJWOo1J6V+gJr+VJryaHU/q0lByB/jiuNb0rsX4lNKxlDpXoG5MttTX+npL2SOavUdyiR41Foq7S9Upu2FkrHRWlsURLHlWDNnE3uM1rbl8rVnTVzGmvlEoAy/2Etn66k76a8D1kLJfOqKbHIGv3+r/oOJe2VPKO1+lWKNeV4FHT3oFEBACMscu/ePWZvb//A+62vr2d2dnYPvF+lfStpW1tby5ydne9HtD8Fa8mtdAytOebW4n91zP/XsKaeATCVSvXA+31U7PlRkeN/EWvFN8aU2fSjMoaPir9TMmcfFZkfFaxp00qgcSH+LKwV8x+VXJogiP9b0KIUQRAEQRAEQRAEQRAE8dCx+bMFIAiCIAiCIAiCIAiCIP7/gxalCIIgCIIgCIIgCIIgiIcOLUoRBEEQBEEQBEEQBEEQDx1alCIIgiAIgiAIgiAIgiAeOrQoRRAEQRAEQRAEQRAEQTx0aFGKIAiCIAiCIAiCIAiCeOjQohRBEARBEMQD4tChQ0ylUrFbt2792aI8UBITE9mMGTP+bDEIgiAIgvg/Bi1KEQRBEARBNOL69ets6tSprF27dszBwYH5+/uzzMxMtn//fsm/i4uLY9euXWNubm4PSVIxJ0+eZEOGDGHe3t6sefPmLCQkhE2YMIGdOXPmT5GHIAiCIAhCClqUIgiCIAiCMODHH39kUVFR7MCBA2zlypWstLSUffXVV6xPnz5s8uTJZv+uvr6e2dvbMx8fH6ZSqR6ixHp27tzJYmNj2d27d9nmzZtZRUUF+/DDD5mbmxt78cUXH7o8BEEQBEEQlqBFKYIgCIIgCAP+8pe/MJVKxQoLC1lWVhZr3749i4yMZDNnzmTff/89b6dSqdjatWvZgAEDmLOzM1u6dKnR8b2NGzcytVrNdu7cyUJDQ5mTkxMbPHgwu337Nnv//fdZYGAgc3d3Z9OmTWNarZb3fffuXZaTk8NatWrFnJ2dWffu3dmhQ4fMynz79m02ZswY1q9fP7Zjxw6WnJzM2rZty7p3785WrVrFcnNzedv8/HwWExPDHBwcmK+vL5s7dy5raGjgv6+trWWjRo1iLi4uzNfXl61evdro31MqH0EQBEEQhCloUYogCIIgCOI//PLLL+yrr75ikydPZs7Ozka/V6vVop//9re/sUGDBrHS0lI2duxYk33evn2bvf766ywvL4999dVX7NChQ2zQoEFs9+7dbPfu3WzTpk0sNzeXbdu2jf/NlClT2Hfffcfy8vJYSUkJGzJkCEtPT2dnz541+W98/fXX7ObNm2zOnDkmfy/IfeXKFdavXz8WHR3NiouL2dq1a9m7777LlixZwtvOnj2b5efnsy+++ILt2bOHHTp0iBUVFYn6UyofQRAEQRCEKZr92QIQBEEQBEE8Kpw7d44BYGFhYbLaDx8+nI0ZM4b/fOHCBaM29fX1bO3atSwoKIgxxtjgwYPZpk2b2M8//8xcXFxYREQE69OnDzt48CB76qmn2KVLl9iGDRvYpUuXmJ+fH2OMsZycHPbVV1+xDRs2sFdeecXo3xAWgyzJ/dZbbzF/f3+2Zs0aplKpWFhYGLt69Sp74YUX2MKFC9nt27fZu+++yz788EOWlJTEGGPs/fffZ61bt+Z9NEU+giAIgiAIU9CiFEEQBEEQxH8AoKh9t27dLLZxcnLiC1KMMebt7c0CAwOZi4uL6L9VVVUxxhgrLS1lWq2WtW/fXtTP3bt3mYeHx33JXVFRwXr06CGqedWzZ09WU1PDLl++zH799Vd279491r17d/57jUbDQkND+c9NkY8gCIIgCMIUtChFEARBEATxH0JCQphKpWKnT5+W1d7UEb/G2NnZiX5WqVQm/5tOp2OMMVZTU8NsbW3ZiRMnmK2traid4UKWIcIC0enTp1mPHj1kyd5UmiIfQRAEQRCEKaimFEEQBEEQxH/QaDQsLS2Nvfnmm6y2ttbo90IBc2vSpUsXptVqWVVVFQsODhb9n4+Pj8m/SU1NZZ6enmzFihUmfy/IHR4ezr777jvRzqpvvvmGubq6statW7OgoCBmZ2fHjh49yn//66+/sjNnztyXfARBEARBEKagRSmCIAiCIAgD3nzzTabVallMTAzbvn07O3v2LKuoqGCvv/661XchMabf9ZSdnc1GjRrFPv30U3bx4kVWWFjIli1bxnbt2mXyb5ydndn69evZrl272IABA9i+ffvYjz/+yI4fP87mzJnDJk2axBjT3yxYWVnJpk6dyk6fPs2++OILtmjRIjZz5kxmY2PDXFxc2Lhx49js2bPZgQMHWFlZGRs9ejSzsbG5L/kIgiAIgiBMQcf3CIIgCIIgDGjXrh0rKipiS5cuZbNmzWLXrl1jXl5eLCoqiq1du/ahyLBhwwa2ZMkSNmvWLHblyhXm6enJYmNjWf/+/c3+zcCBA9m3337Lli1bxoYPH85+//135u/vzx5//HF+u16rVq3Y7t272ezZs1mnTp2YRqNh48aNYwsWLOD9rFy5ktXU1LDMzEzm6urKZs2axX777bf7lo8gCIIgCKIxKiit6EkQBEEQBEEQBEEQBEEQ9wkd3yMIgiAIgiAIgiAIgiAeOrQoRRAEQRAEQRAEQRAEQTx0aFGKIAiCIAiCIAiCIAiCeOjQohRBEARBEARBEARBEATx0KFFKYIgCIIgCIIgCIIgCOKhQ4tSBEEQBEEQBEEQBEEQxEOHFqUIgiAIgiAIgiAIgiCIhw4tShEEQRAEQRAEQRAEQRAPHVqUIgiCIAiCIAiCIAiCIB46tChFEARBEARBEARBEARBPHRoUYogCIIgCIIgCIIgCIJ46NCiFEEQBEEQBEEQBEEQBPHQ+X8gBrWffrEjMAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation fold statistics:\n",
            "\n",
            "Fold 1 class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.486056\n",
            "624     7.904382\n",
            "330     6.278884\n",
            "740     6.231076\n",
            "310     6.183267\n",
            "         ...    \n",
            "950     0.015936\n",
            "949     0.015936\n",
            "933     0.015936\n",
            "622     0.015936\n",
            "670     0.015936\n",
            "Name: proportion, Length: 94, dtype: float64\n",
            "\n",
            "Fold 2 class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.486056\n",
            "624     7.904382\n",
            "330     6.278884\n",
            "740     6.231076\n",
            "310     6.183267\n",
            "         ...    \n",
            "921     0.015936\n",
            "654     0.015936\n",
            "814     0.015936\n",
            "660     0.015936\n",
            "652     0.015936\n",
            "Name: proportion, Length: 96, dtype: float64\n",
            "\n",
            "Fold 3 class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.486056\n",
            "624     7.904382\n",
            "330     6.278884\n",
            "740     6.231076\n",
            "310     6.183267\n",
            "         ...    \n",
            "443     0.015936\n",
            "622     0.015936\n",
            "933     0.015936\n",
            "653     0.015936\n",
            "654     0.015936\n",
            "Name: proportion, Length: 95, dtype: float64\n",
            "\n",
            "Fold 4 class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.486056\n",
            "624     7.904382\n",
            "330     6.278884\n",
            "740     6.231076\n",
            "310     6.183267\n",
            "         ...    \n",
            "654     0.015936\n",
            "933     0.015936\n",
            "652     0.015936\n",
            "755     0.015936\n",
            "950     0.015936\n",
            "Name: proportion, Length: 95, dtype: float64\n",
            "\n",
            "Fold 5 class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.503666\n",
            "624     7.905642\n",
            "330     6.279885\n",
            "740     6.216130\n",
            "310     6.184252\n",
            "         ...    \n",
            "755     0.015939\n",
            "622     0.015939\n",
            "439     0.015939\n",
            "921     0.015939\n",
            "760     0.015939\n",
            "Name: proportion, Length: 94, dtype: float64\n",
            "\n",
            "Comparison of class distributions across folds:\n",
            "          Fold 1    Fold 2    Fold 3    Fold 4    Fold 5\n",
            "Crm Cd                                                  \n",
            "510     0.104861  0.104861  0.104861  0.104861  0.105037\n",
            "624     0.079044  0.079044  0.079044  0.079044  0.079056\n",
            "330     0.062789  0.062789  0.062789  0.062789  0.062799\n",
            "740     0.062311  0.062311  0.062311  0.062311  0.062161\n",
            "310     0.061833  0.061833  0.061833  0.061833  0.061843\n",
            "...          ...       ...       ...       ...       ...\n",
            "622     0.000159  0.000159  0.000159  0.000159  0.000159\n",
            "670     0.000159  0.000159  0.000159  0.000159  0.000159\n",
            "439          NaN  0.000159  0.000159  0.000159  0.000159\n",
            "654          NaN  0.000159  0.000159  0.000159       NaN\n",
            "652          NaN  0.000159  0.000159  0.000159       NaN\n",
            "\n",
            "[97 rows x 5 columns]\n",
            "\n",
            "Overall Data Split Statistics:\n",
            "\n",
            "Training set shape: (31374, 14)\n",
            "Test set shape: (13447, 14)\n",
            "\n",
            "Training set class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.489577\n",
            "624     7.904634\n",
            "330     6.279085\n",
            "740     6.228087\n",
            "310     6.183464\n",
            "         ...    \n",
            "653     0.009562\n",
            "921     0.009562\n",
            "654     0.009562\n",
            "949     0.009562\n",
            "652     0.009562\n",
            "Name: proportion, Length: 97, dtype: float64\n",
            "\n",
            "Test set class distribution (proportions):\n",
            "Crm Cd\n",
            "510    10.485610\n",
            "624     7.905109\n",
            "330     6.276493\n",
            "740     6.224437\n",
            "310     6.179817\n",
            "         ...    \n",
            "654     0.014873\n",
            "652     0.014873\n",
            "949     0.014873\n",
            "622     0.014873\n",
            "760     0.014873\n",
            "Name: proportion, Length: 97, dtype: float64\n",
            "\n",
            "Processed datasets saved and ready for model training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iZpFzog8tsP"
      },
      "source": [
        "### **2. Experiment with k-NN Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Initialize the imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit imputer on training data and transform both training and test data\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"Calculate all required metrics.\"\"\"\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def run_kfold_experiment(X, y, k_value, n_splits=5):\n",
        "    \"\"\"Run k-fold cross-validation for a specific k value.\"\"\"\n",
        "    knn = KNeighborsClassifier(n_neighbors=k_value)\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "        # Split data\n",
        "        X_train_fold = X.iloc[train_idx]\n",
        "        y_train_fold = y.iloc[train_idx]\n",
        "        X_val_fold = X.iloc[val_idx]\n",
        "        y_val_fold = y.iloc[val_idx]\n",
        "\n",
        "        # Impute missing values for this fold\n",
        "        fold_imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_fold_imputed = pd.DataFrame(\n",
        "            fold_imputer.fit_transform(X_train_fold),\n",
        "            columns=X_train_fold.columns\n",
        "        )\n",
        "        X_val_fold_imputed = pd.DataFrame(\n",
        "            fold_imputer.transform(X_val_fold),\n",
        "            columns=X_val_fold.columns\n",
        "        )\n",
        "\n",
        "        # Train and predict\n",
        "        knn.fit(X_train_fold_imputed, y_train_fold)\n",
        "        y_pred = knn.predict(X_val_fold_imputed)\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics = calculate_metrics(y_val_fold, y_pred)\n",
        "        metrics['fold'] = fold\n",
        "        fold_metrics.append(metrics)\n",
        "\n",
        "    return pd.DataFrame(fold_metrics)\n",
        "\n",
        "# Step 1: Define k values to experiment with\n",
        "k_values = [5, 7, 11, 15, 21]  # Not too small, not too large\n",
        "\n",
        "# Dictionary to store results for all k values\n",
        "all_results = {}\n",
        "\n",
        "print(\"\\nStarting k-NN experiments with 5-fold cross-validation...\")\n",
        "print(\"\\nStep 2 & 3: Running cross-validation and calculating metrics for each k value\")\n",
        "\n",
        "# Run experiments for each k value\n",
        "for k in k_values:\n",
        "    print(f\"\\nExperimenting with k={k}\")\n",
        "    results_df = run_kfold_experiment(X_train, y_train, k)\n",
        "    all_results[k] = results_df\n",
        "\n",
        "    print(f\"\\nResults for k={k}:\")\n",
        "    print(\"\\nMetrics for each fold:\")\n",
        "    print(results_df.round(4))\n",
        "\n",
        "    print(\"\\nAverage metrics across folds:\")\n",
        "    mean_metrics = results_df.mean().round(4)\n",
        "    std_metrics = results_df.std().round(4)\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        print(f\"{metric}: {mean_metrics[metric]} (±{std_metrics[metric]})\")\n",
        "\n",
        "# Step 4 & 7: Analyze results and find best k value\n",
        "print(\"\\nStep 4 & 7: Analyzing results across all k values\")\n",
        "\n",
        "# Calculate mean performance for each k value\n",
        "summary_results = {}\n",
        "for k, results in all_results.items():\n",
        "    summary_results[k] = results.mean()[['accuracy', 'precision', 'recall', 'f1']]\n",
        "\n",
        "summary_df = pd.DataFrame(summary_results).T\n",
        "print(\"\\nMean performance metrics for each k value:\")\n",
        "print(summary_df.round(4))\n",
        "\n",
        "# Find best k value based on F1 score\n",
        "best_k = summary_df['f1'].idxmax()\n",
        "print(f\"\\nBest k value based on F1 score: {best_k}\")\n",
        "\n",
        "# Step 8: Train final model with best k value on full training data and evaluate on test set\n",
        "print(\"\\nStep 8: Evaluating best model on test set\")\n",
        "final_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# Train the model on the imputed training data\n",
        "final_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Make predictions on the imputed test data\n",
        "y_test_pred = final_model.predict(X_test_imputed)\n",
        "\n",
        "# Calculate final metrics\n",
        "final_metrics = calculate_metrics(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nFinal model performance on test set:\")\n",
        "for metric, value in final_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cizwgziq53XP",
        "outputId": "5fc344f4-4a14-49b4-d18a-89e868a00838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting k-NN experiments with 5-fold cross-validation...\n",
            "\n",
            "Step 2 & 3: Running cross-validation and calculating metrics for each k value\n",
            "\n",
            "Experimenting with k=5\n",
            "\n",
            "Results for k=5:\n",
            "\n",
            "Metrics for each fold:\n",
            "   accuracy  precision  recall      f1  fold\n",
            "0    0.2660     0.2426  0.2660  0.2452     1\n",
            "1    0.2652     0.2427  0.2652  0.2444     2\n",
            "2    0.2657     0.2428  0.2657  0.2454     3\n",
            "3    0.2691     0.2470  0.2691  0.2483     4\n",
            "4    0.2691     0.2458  0.2691  0.2479     5\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.267 (±0.0019)\n",
            "precision: 0.2442 (±0.0021)\n",
            "recall: 0.267 (±0.0019)\n",
            "f1: 0.2462 (±0.0017)\n",
            "\n",
            "Experimenting with k=7\n",
            "\n",
            "Results for k=7:\n",
            "\n",
            "Metrics for each fold:\n",
            "   accuracy  precision  recall      f1  fold\n",
            "0    0.2782     0.2437  0.2782  0.2524     1\n",
            "1    0.2764     0.2428  0.2764  0.2503     2\n",
            "2    0.2781     0.2439  0.2781  0.2523     3\n",
            "3    0.2812     0.2460  0.2812  0.2545     4\n",
            "4    0.2809     0.2452  0.2809  0.2542     5\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.279 (±0.002)\n",
            "precision: 0.2443 (±0.0012)\n",
            "recall: 0.279 (±0.002)\n",
            "f1: 0.2527 (±0.0017)\n",
            "\n",
            "Experimenting with k=11\n",
            "\n",
            "Results for k=11:\n",
            "\n",
            "Metrics for each fold:\n",
            "   accuracy  precision  recall      f1  fold\n",
            "0    0.2891     0.2439  0.2891  0.2548     1\n",
            "1    0.2878     0.2460  0.2878  0.2542     2\n",
            "2    0.2919     0.2473  0.2919  0.2579     3\n",
            "3    0.2929     0.2473  0.2929  0.2581     4\n",
            "4    0.2907     0.2440  0.2907  0.2560     5\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.2905 (±0.0021)\n",
            "precision: 0.2457 (±0.0017)\n",
            "recall: 0.2905 (±0.0021)\n",
            "f1: 0.2562 (±0.0017)\n",
            "\n",
            "Experimenting with k=15\n",
            "\n",
            "Results for k=15:\n",
            "\n",
            "Metrics for each fold:\n",
            "   accuracy  precision  recall      f1  fold\n",
            "0    0.2959     0.2461  0.2959  0.2572     1\n",
            "1    0.2948     0.2452  0.2948  0.2558     2\n",
            "2    0.2969     0.2481  0.2969  0.2582     3\n",
            "3    0.2981     0.2508  0.2981  0.2595     4\n",
            "4    0.2963     0.2441  0.2963  0.2570     5\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.2964 (±0.0012)\n",
            "precision: 0.2469 (±0.0026)\n",
            "recall: 0.2964 (±0.0012)\n",
            "f1: 0.2575 (±0.0014)\n",
            "\n",
            "Experimenting with k=21\n",
            "\n",
            "Results for k=21:\n",
            "\n",
            "Metrics for each fold:\n",
            "   accuracy  precision  recall      f1  fold\n",
            "0    0.3009     0.2515  0.3009  0.2577     1\n",
            "1    0.2991     0.2461  0.2991  0.2552     2\n",
            "2    0.3005     0.2478  0.3005  0.2573     3\n",
            "3    0.3026     0.2490  0.3026  0.2590     4\n",
            "4    0.3004     0.2459  0.3004  0.2568     5\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3007 (±0.0013)\n",
            "precision: 0.2481 (±0.0023)\n",
            "recall: 0.3007 (±0.0013)\n",
            "f1: 0.2572 (±0.0014)\n",
            "\n",
            "Step 4 & 7: Analyzing results across all k values\n",
            "\n",
            "Mean performance metrics for each k value:\n",
            "    accuracy  precision  recall      f1\n",
            "5     0.2670     0.2442  0.2670  0.2462\n",
            "7     0.2790     0.2443  0.2790  0.2527\n",
            "11    0.2905     0.2457  0.2905  0.2562\n",
            "15    0.2964     0.2469  0.2964  0.2575\n",
            "21    0.3007     0.2481  0.3007  0.2572\n",
            "\n",
            "Best k value based on F1 score: 15\n",
            "\n",
            "Step 8: Evaluating best model on test set\n",
            "\n",
            "Final model performance on test set:\n",
            "accuracy: 0.2996\n",
            "precision: 0.2503\n",
            "recall: 0.2996\n",
            "f1: 0.2609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEDJDHHW8tsP"
      },
      "source": [
        "### **3. Experiment with Naïve Bayes Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tambahan library yang dibutuhkan\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Step 1: Eksperimen dengan 5-fold cross validation\n",
        "print(\"Step 1: Melakukan eksperimen dengan 5-fold cross validation\")\n",
        "nb_models = []\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_scaled, y_train), 1):\n",
        "    print(f\"\\nFold ke-{fold}\")\n",
        "\n",
        "    # Split data untuk fold ini\n",
        "    X_fold_train = X_train_scaled.iloc[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx]\n",
        "    X_fold_val = X_train_scaled.iloc[val_idx]\n",
        "    y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "    # Train model Naive Bayes\n",
        "    nb_model = GaussianNB()\n",
        "    nb_model.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "    # Simpan model\n",
        "    nb_models.append(nb_model)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = nb_model.predict(X_fold_val)\n",
        "    y_pred_proba = nb_model.predict_proba(X_fold_val)\n",
        "\n",
        "    # Simpan hasil untuk step berikutnya\n",
        "    fold_results.append({\n",
        "        'fold': fold,\n",
        "        'model': nb_model,\n",
        "        'y_true': y_fold_val,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    })\n",
        "\n",
        "# Step 2: Menghitung metrik untuk setiap fold\n",
        "print(\"\\nStep 2: Menghitung metrik untuk setiap fold\")\n",
        "metrics_results = []\n",
        "\n",
        "for result in fold_results:\n",
        "    # Persiapkan data untuk ROC AUC\n",
        "    unique_classes = np.unique(result['y_true'])\n",
        "    y_true_bin = label_binarize(result['y_true'], classes=unique_classes)\n",
        "\n",
        "    # Hitung metrik\n",
        "    metrics = {\n",
        "        'fold': result['fold'],\n",
        "        'accuracy': accuracy_score(result['y_true'], result['y_pred']),\n",
        "        'precision': precision_score(result['y_true'], result['y_pred'], average='weighted'),\n",
        "        'recall': recall_score(result['y_true'], result['y_pred'], average='weighted'),\n",
        "        'f1': f1_score(result['y_true'], result['y_pred'], average='weighted'),\n",
        "        'auc_roc': roc_auc_score(y_true_bin,\n",
        "                                label_binarize(result['y_pred'], classes=unique_classes),\n",
        "                                average='weighted',\n",
        "                                multi_class='ovr')\n",
        "    }\n",
        "    metrics_results.append(metrics)\n",
        "\n",
        "    print(f\"\\nMetrik untuk Fold {metrics['fold']}:\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1-score: {metrics['f1']:.4f}\")\n",
        "    print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "\n",
        "# Step 3: Analisis hasil performa kelima model\n",
        "print(\"\\nStep 3: Analisis hasil performa kelima model\")\n",
        "results_df = pd.DataFrame(metrics_results)\n",
        "print(\"\\nRingkasan statistik untuk semua fold:\")\n",
        "print(results_df.describe())\n",
        "\n",
        "print(\"\\nPerbandingan performa antar fold:\")\n",
        "print(results_df)\n",
        "\n",
        "# Step 4: Analisis hasil performa untuk menentukan model terbaik\n",
        "print(\"\\nStep 4: Analisis untuk menentukan model terbaik\")\n",
        "# Menentukan model terbaik berdasarkan F1-score\n",
        "best_fold_idx = results_df['f1'].argmax()\n",
        "best_model = nb_models[best_fold_idx]\n",
        "best_metrics = results_df.iloc[best_fold_idx]\n",
        "\n",
        "print(f\"\\nModel terbaik ditemukan pada fold ke-{best_fold_idx + 1}\")\n",
        "print(f\"Metrics model terbaik pada data validasi:\")\n",
        "print(f\"Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
        "print(f\"F1-score: {best_metrics['f1']:.4f}\")\n",
        "print(f\"AUC-ROC: {best_metrics['auc_roc']:.4f}\")\n",
        "\n",
        "# Step 5: Evaluasi model terbaik pada data test\n",
        "print(\"\\nStep 5: Evaluasi model terbaik pada data test\")\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "y_test_pred_proba = best_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Hitung metrik untuk data test\n",
        "unique_classes = np.unique(y_test)\n",
        "y_test_bin = label_binarize(y_test, classes=unique_classes)\n",
        "y_test_pred_bin = label_binarize(y_test_pred, classes=unique_classes)\n",
        "\n",
        "test_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, y_test_pred),\n",
        "    'precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
        "    'recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
        "    'f1': f1_score(y_test, y_test_pred, average='weighted'),\n",
        "    'auc_roc': roc_auc_score(y_test_bin, y_test_pred_bin, average='weighted', multi_class='ovr')\n",
        "}\n",
        "\n",
        "print(\"\\nPerforma model terbaik pada data test:\")\n",
        "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
        "print(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
        "print(f\"AUC-ROC: {test_metrics['auc_roc']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVtlLipFpo82",
        "outputId": "3eda410a-0329-4588-bf6c-da81b450bf54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Melakukan eksperimen dengan 5-fold cross validation\n",
            "\n",
            "Fold ke-1\n",
            "\n",
            "Fold ke-2\n",
            "\n",
            "Fold ke-3\n",
            "\n",
            "Fold ke-4\n",
            "\n",
            "Fold ke-5\n",
            "\n",
            "Step 2: Menghitung metrik untuk setiap fold\n",
            "\n",
            "Metrik untuk Fold 1:\n",
            "Accuracy: 0.0206\n",
            "Precision: 0.0697\n",
            "Recall: 0.0206\n",
            "F1-score: 0.0204\n",
            "AUC-ROC: 0.5078\n",
            "\n",
            "Metrik untuk Fold 2:\n",
            "Accuracy: 0.0164\n",
            "Precision: 0.0744\n",
            "Recall: 0.0164\n",
            "F1-score: 0.0155\n",
            "AUC-ROC: 0.5065\n",
            "\n",
            "Metrik untuk Fold 3:\n",
            "Accuracy: 0.0200\n",
            "Precision: 0.0725\n",
            "Recall: 0.0200\n",
            "F1-score: 0.0182\n",
            "AUC-ROC: 0.5077\n",
            "\n",
            "Metrik untuk Fold 4:\n",
            "Accuracy: 0.0253\n",
            "Precision: 0.0705\n",
            "Recall: 0.0253\n",
            "F1-score: 0.0222\n",
            "AUC-ROC: 0.5097\n",
            "\n",
            "Metrik untuk Fold 5:\n",
            "Accuracy: 0.0172\n",
            "Precision: 0.0600\n",
            "Recall: 0.0172\n",
            "F1-score: 0.0171\n",
            "AUC-ROC: 0.5066\n",
            "\n",
            "Step 3: Analisis hasil performa kelima model\n",
            "\n",
            "Ringkasan statistik untuk semua fold:\n",
            "           fold  accuracy  precision    recall        f1   auc_roc\n",
            "count  5.000000  5.000000   5.000000  5.000000  5.000000  5.000000\n",
            "mean   3.000000  0.019879   0.069404  0.019879  0.018674  0.507666\n",
            "std    1.581139  0.003494   0.005578  0.003494  0.002669  0.001270\n",
            "min    1.000000  0.016379   0.059992  0.016379  0.015464  0.506540\n",
            "25%    2.000000  0.017233   0.069667  0.017233  0.017078  0.506570\n",
            "50%    3.000000  0.019955   0.070456  0.019955  0.018236  0.507728\n",
            "75%    4.000000  0.020554   0.072474  0.020554  0.020372  0.507837\n",
            "max    5.000000  0.025276   0.074431  0.025276  0.022219  0.509653\n",
            "\n",
            "Perbandingan performa antar fold:\n",
            "   fold  accuracy  precision    recall        f1   auc_roc\n",
            "0     1  0.020554   0.069667  0.020554  0.020372  0.507837\n",
            "1     2  0.016379   0.074431  0.016379  0.015464  0.506540\n",
            "2     3  0.019955   0.072474  0.019955  0.018236  0.507728\n",
            "3     4  0.025276   0.070456  0.025276  0.022219  0.509653\n",
            "4     5  0.017233   0.059992  0.017233  0.017078  0.506570\n",
            "\n",
            "Step 4: Analisis untuk menentukan model terbaik\n",
            "\n",
            "Model terbaik ditemukan pada fold ke-4\n",
            "Metrics model terbaik pada data validasi:\n",
            "Accuracy: 0.0253\n",
            "Precision: 0.0705\n",
            "Recall: 0.0253\n",
            "F1-score: 0.0222\n",
            "AUC-ROC: 0.5097\n",
            "\n",
            "Step 5: Evaluasi model terbaik pada data test\n",
            "\n",
            "Performa model terbaik pada data test:\n",
            "Accuracy: 0.0255\n",
            "Precision: 0.0700\n",
            "Recall: 0.0255\n",
            "F1-score: 0.0225\n",
            "AUC-ROC: 0.5098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loXLSMK58tsP"
      },
      "source": [
        "### **4. Experiment with Logistic Regression Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang dibutuhkan\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    train_size=0.1,  # mengambil 10% data\n",
        "    random_state=42,  # untuk reproducibility\n",
        "    stratify=y_train  # memastikan distribusi kelas tetap seimbang\n",
        ")\n",
        "\n",
        "# Step 1: Eksperimen model dengan 5-fold cross validation\n",
        "print(\"\\nStep 1: Eksperimen Logistic Regression dengan 5-fold cross validation\")\n",
        "# Inisialisasi model dengan parameter yang dioptimalkan\n",
        "lr_models = []\n",
        "fold_results = []\n",
        "\n",
        "# Pengaturan model yang lebih efisien\n",
        "lr_params = {\n",
        "    'solver': 'lbfgs',  # Solver yang efisien untuk multiclass\n",
        "    'max_iter': 500,    # Mengurangi iterasi maksimum\n",
        "    'multi_class': 'multinomial',\n",
        "    'n_jobs': -1       # Menggunakan semua core CPU\n",
        "}\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_sampled, y_train_sampled), 1):\n",
        "    print(f\"Training fold ke-{fold}...\")\n",
        "\n",
        "    # Split data\n",
        "    X_fold_train = X_train_sampled.iloc[train_idx]\n",
        "    y_fold_train = y_train_sampled.iloc[train_idx]\n",
        "    X_fold_val = X_train_sampled.iloc[val_idx]\n",
        "    y_fold_val = y_train_sampled.iloc[val_idx]\n",
        "\n",
        "    # Train model\n",
        "    lr = LogisticRegression(**lr_params)\n",
        "    lr.fit(X_fold_train, y_fold_train)\n",
        "    lr_models.append(lr)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = lr.predict(X_fold_val)\n",
        "    y_pred_proba = lr.predict_proba(X_fold_val)\n",
        "\n",
        "    # Simpan hasil\n",
        "    fold_results.append({\n",
        "        'fold': fold,\n",
        "        'y_true': y_fold_val,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    })\n",
        "\n",
        "# Step 2: Menghitung metrik untuk setiap fold\n",
        "print(\"\\nStep 2: Menghitung metrik evaluasi untuk setiap fold\")\n",
        "metrics_results = []\n",
        "\n",
        "for result in fold_results:\n",
        "    print(f\"\\nMenghitung metrik untuk fold {result['fold']}...\")\n",
        "    metrics = {\n",
        "        'fold': result['fold'],\n",
        "        'accuracy': accuracy_score(result['y_true'], result['y_pred']),\n",
        "        'precision': precision_score(result['y_true'], result['y_pred'], average='weighted'),\n",
        "        'recall': recall_score(result['y_true'], result['y_pred'], average='weighted'),\n",
        "        'f1': f1_score(result['y_true'], result['y_pred'], average='weighted')\n",
        "    }\n",
        "\n",
        "    # Hitung AUC-ROC\n",
        "    try:\n",
        "        # Persiapkan data untuk ROC AUC\n",
        "        unique_classes = np.unique(result['y_true'])\n",
        "        y_true_bin = label_binarize(result['y_true'], classes=unique_classes)\n",
        "        y_pred_bin = label_binarize(result['y_pred'], classes=unique_classes)\n",
        "        metrics['auc_roc'] = roc_auc_score(y_true_bin, y_pred_bin, average='weighted', multi_class='ovr')\n",
        "    except:\n",
        "        metrics['auc_roc'] = np.nan\n",
        "\n",
        "    metrics_results.append(metrics)\n",
        "\n",
        "    # Print hasil metrics\n",
        "    print(f\"Fold {metrics['fold']} metrics:\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1-score: {metrics['f1']:.4f}\")\n",
        "    print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "\n",
        "# Step 3: Analisis performa kelima model\n",
        "print(\"\\nStep 3: Analisis performa kelima model\")\n",
        "results_df = pd.DataFrame(metrics_results)\n",
        "print(\"\\nStatistik deskriptif performa model:\")\n",
        "print(results_df.describe())\n",
        "\n",
        "print(\"\\nPerforma setiap fold:\")\n",
        "print(results_df)\n",
        "\n",
        "# Step 4: Analisis untuk menentukan model terbaik\n",
        "print(\"\\nStep 4: Menentukan model terbaik\")\n",
        "best_fold_idx = results_df['f1'].argmax()\n",
        "best_fold_metrics = results_df.iloc[best_fold_idx]\n",
        "\n",
        "print(f\"\\nModel terbaik ada pada fold ke-{best_fold_idx + 1}\")\n",
        "print(\"Metrik model terbaik:\")\n",
        "for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc_roc']:\n",
        "    print(f\"{metric}: {best_fold_metrics[metric]:.4f}\")\n",
        "\n",
        "# Step 5: Evaluasi model terbaik pada data test\n",
        "print(\"\\nStep 5: Evaluasi model terbaik pada data test\")\n",
        "best_model = lr_models[best_fold_idx]\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Hitung metrik final\n",
        "final_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, y_test_pred),\n",
        "    'precision': precision_score(y_test, y_test_pred, average='weighted'),\n",
        "    'recall': recall_score(y_test, y_test_pred, average='weighted'),\n",
        "    'f1': f1_score(y_test, y_test_pred, average='weighted')\n",
        "}\n",
        "\n",
        "# Hitung AUC-ROC untuk test set\n",
        "try:\n",
        "    unique_classes = np.unique(y_test)\n",
        "    y_test_bin = label_binarize(y_test, classes=unique_classes)\n",
        "    y_test_pred_bin = label_binarize(y_test_pred, classes=unique_classes)\n",
        "    final_metrics['auc_roc'] = roc_auc_score(y_test_bin, y_test_pred_bin, average='weighted', multi_class='ovr')\n",
        "except:\n",
        "    final_metrics['auc_roc'] = np.nan\n",
        "\n",
        "print(\"\\nHasil evaluasi model terbaik pada data test:\")\n",
        "for metric, value in final_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcmMXx1mpZwL",
        "outputId": "ae814477-06ec-4690-96e6-4c09cac270a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mengambil 10% sampel data...\n",
            "Ukuran data original: 685032\n",
            "Ukuran data setelah sampling: 68503\n",
            "\n",
            "Step 1: Eksperimen Logistic Regression dengan 5-fold cross validation\n",
            "Training fold ke-1...\n",
            "Training fold ke-2...\n",
            "Training fold ke-3...\n",
            "Training fold ke-4...\n",
            "Training fold ke-5...\n",
            "\n",
            "Step 2: Menghitung metrik evaluasi untuk setiap fold\n",
            "\n",
            "Menghitung metrik untuk fold 1...\n",
            "Fold 1 metrics:\n",
            "Accuracy: 0.2614\n",
            "Precision: 0.1825\n",
            "Recall: 0.2614\n",
            "F1-score: 0.2062\n",
            "AUC-ROC: 0.6067\n",
            "\n",
            "Menghitung metrik untuk fold 2...\n",
            "Fold 2 metrics:\n",
            "Accuracy: 0.2636\n",
            "Precision: 0.1909\n",
            "Recall: 0.2636\n",
            "F1-score: 0.2082\n",
            "AUC-ROC: 0.6079\n",
            "\n",
            "Menghitung metrik untuk fold 3...\n",
            "Fold 3 metrics:\n",
            "Accuracy: 0.2634\n",
            "Precision: 0.2111\n",
            "Recall: 0.2634\n",
            "F1-score: 0.2094\n",
            "AUC-ROC: 0.6076\n",
            "\n",
            "Menghitung metrik untuk fold 4...\n",
            "Fold 4 metrics:\n",
            "Accuracy: 0.2569\n",
            "Precision: 0.1918\n",
            "Recall: 0.2569\n",
            "F1-score: 0.2036\n",
            "AUC-ROC: 0.6043\n",
            "\n",
            "Menghitung metrik untuk fold 5...\n",
            "Fold 5 metrics:\n",
            "Accuracy: 0.2603\n",
            "Precision: 0.1921\n",
            "Recall: 0.2603\n",
            "F1-score: 0.2062\n",
            "AUC-ROC: 0.6060\n",
            "\n",
            "Step 3: Analisis performa kelima model\n",
            "\n",
            "Statistik deskriptif performa model:\n",
            "           fold  accuracy  precision    recall        f1   auc_roc\n",
            "count  5.000000  5.000000   5.000000  5.000000  5.000000  5.000000\n",
            "mean   3.000000  0.261127   0.193677  0.261127  0.206726  0.606525\n",
            "std    1.581139  0.002716   0.010505  0.002716  0.002229  0.001434\n",
            "min    1.000000  0.256934   0.182460  0.256934  0.203600  0.604339\n",
            "25%    2.000000  0.260292   0.190922  0.260292  0.206172  0.606037\n",
            "50%    3.000000  0.261441   0.191806  0.261441  0.206215  0.606690\n",
            "75%    4.000000  0.263411   0.192138  0.263411  0.208206  0.607632\n",
            "max    5.000000  0.263557   0.211059  0.263557  0.209437  0.607925\n",
            "\n",
            "Performa setiap fold:\n",
            "   fold  accuracy  precision    recall        f1   auc_roc\n",
            "0     1  0.261441   0.182460  0.261441  0.206172  0.606690\n",
            "1     2  0.263557   0.190922  0.263557  0.208206  0.607925\n",
            "2     3  0.263411   0.211059  0.263411  0.209437  0.607632\n",
            "3     4  0.256934   0.191806  0.256934  0.203600  0.604339\n",
            "4     5  0.260292   0.192138  0.260292  0.206215  0.606037\n",
            "\n",
            "Step 4: Menentukan model terbaik\n",
            "\n",
            "Model terbaik ada pada fold ke-3\n",
            "Metrik model terbaik:\n",
            "accuracy: 0.2634\n",
            "precision: 0.2111\n",
            "recall: 0.2634\n",
            "f1: 0.2094\n",
            "auc_roc: 0.6076\n",
            "\n",
            "Step 5: Evaluasi model terbaik pada data test\n",
            "\n",
            "Hasil evaluasi model terbaik pada data test:\n",
            "accuracy: 0.2615\n",
            "precision: 0.1969\n",
            "recall: 0.2615\n",
            "f1: 0.2059\n",
            "auc_roc: 0.6066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Xv1gcb8tsQ"
      },
      "source": [
        "### **5. Experiment with SVM Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load the dataset\n",
        "print(\"Loading the dataset...\")\n",
        "data = pd.read_csv('cleaned_crime_data.csv')\n",
        "\n",
        "# 2. Sample 10% of the data for efficiency\n",
        "print(\"Sampling 10% of the data...\")\n",
        "data = data.sample(frac=0.01, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 3. Drop unnecessary columns\n",
        "print(\"Dropping unnecessary columns...\")\n",
        "data = data.drop(columns=['Datetime', 'AREA NAME', 'LOCATION', 'Weapon Used Cd'])\n",
        "\n",
        "# 4. Ensure no datetime columns remain\n",
        "data = data.select_dtypes(exclude=['datetime'])\n",
        "\n",
        "# 5. Transform categorical variables\n",
        "print(\"Mapping categorical variables...\")\n",
        "day_of_week_mapping = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7}\n",
        "data['Day of Week'] = data['Day of Week'].map(day_of_week_mapping)\n",
        "\n",
        "time_of_day_mapping = {'Day': 0, 'Night': 1}\n",
        "data['Time_of_Day'] = data['Time_of_Day'].map(time_of_day_mapping)\n",
        "\n",
        "vict_sex_mapping = {'M': 1, 'X': 3, 'F': 2}\n",
        "data['Vict Sex'] = data['Vict Sex'].map(vict_sex_mapping)\n",
        "\n",
        "# 6. Encode 'Vict Descent' using LabelEncoder\n",
        "print(\"Encoding 'Vict Descent' with LabelEncoder...\")\n",
        "label_encoder = LabelEncoder()\n",
        "data['Vict Descent'] = label_encoder.fit_transform(data['Vict Descent'])\n",
        "\n",
        "# 7. Handle missing values\n",
        "print(\"Handling missing values...\")\n",
        "data['Premis Cd'].fillna(data['Premis Cd'].mode()[0], inplace=True)\n",
        "\n",
        "# 8. Prepare features and target\n",
        "print(\"Preparing features and target...\")\n",
        "X = data.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)\n",
        "y = data['Crm Cd']\n",
        "\n",
        "# 9. Filter out rare classes (less than 5 instances)\n",
        "print(\"Filtering rare classes with fewer than 5 instances...\")\n",
        "value_counts = y.value_counts()\n",
        "classes_to_keep = value_counts[value_counts >= 5].index\n",
        "data_filtered = data[data['Crm Cd'].isin(classes_to_keep)]\n",
        "X = data_filtered.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)\n",
        "y = data_filtered['Crm Cd']\n",
        "\n",
        "# 10. Split data with stratified sampling\n",
        "print(\"Splitting data into training and test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# 11. Scale features\n",
        "print(\"Scaling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 12. Convert back to DataFrame to maintain column names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# 13. Set up SVM cross-validation with multiple kernels and C values\n",
        "print(\"Setting up cross-validation...\")\n",
        "kernel_types = ['linear', 'rbf']\n",
        "C_values = [0.1, 1, 10]\n",
        "results = []\n",
        "\n",
        "for kernel in tqdm(kernel_types, desc=\"Kernel Loop\"):\n",
        "    for C in tqdm(C_values, desc=f\"Kernel: {kernel}\", leave=False):\n",
        "        model = svm.SVC(kernel=kernel, C=C, probability=True, random_state=42)\n",
        "        strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        # Lists to store metrics for each fold\n",
        "        accuracies, precisions, recalls, f1_scores, auc_rocs = [], [], [], [], []\n",
        "\n",
        "        for fold, (train_index, val_index) in enumerate(tqdm(strat_k_fold.split(X_train_scaled, y_train), desc=\"Folds\", leave=False), 1):\n",
        "            X_train_fold, X_val_fold = X_train_scaled.iloc[train_index], X_train_scaled.iloc[val_index]\n",
        "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "            model.fit(X_train_fold, y_train_fold)\n",
        "            y_pred = model.predict(X_val_fold)\n",
        "            y_pred_proba = model.predict_proba(X_val_fold)\n",
        "\n",
        "            # Calculate metrics\n",
        "            accuracies.append(accuracy_score(y_val_fold, y_pred))\n",
        "            precisions.append(precision_score(y_val_fold, y_pred, average='weighted'))\n",
        "            recalls.append(recall_score(y_val_fold, y_pred, average='weighted'))\n",
        "            f1_scores.append(f1_score(y_val_fold, y_pred, average='weighted'))\n",
        "\n",
        "            lb = LabelBinarizer()\n",
        "            y_val_binarized = lb.fit_transform(y_val_fold)\n",
        "            auc_rocs.append(roc_auc_score(y_val_binarized, y_pred_proba, multi_class='ovr'))\n",
        "\n",
        "        # Average metrics for each parameter combo\n",
        "        results.append({\n",
        "            'Kernel': kernel,\n",
        "            'C': C,\n",
        "            'Accuracy': np.mean(accuracies),\n",
        "            'Precision': np.mean(precisions),\n",
        "            'Recall': np.mean(recalls),\n",
        "            'F1-Score': np.mean(f1_scores),\n",
        "            'AUC-ROC': np.mean(auc_rocs)\n",
        "        })\n",
        "\n",
        "# 14. Display results\n",
        "print(\"\\nResults for each kernel and C value:\")\n",
        "for result in results:\n",
        "    print(f\"Kernel: {result['Kernel']}, C: {result['C']}\")\n",
        "    print(f\"  Accuracy: {result['Accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {result['Precision']:.4f}\")\n",
        "    print(f\"  Recall: {result['Recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {result['F1-Score']:.4f}\")\n",
        "    print(f\"  AUC-ROC: {result['AUC-ROC']:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "-DlAlsc6uDPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a0b14c-77a7-40e2-fb9b-8f6b1ef5d182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n",
            "Sampling 10% of the data...\n",
            "Dropping unnecessary columns...\n",
            "Mapping categorical variables...\n",
            "Encoding 'Vict Descent' with LabelEncoder...\n",
            "Handling missing values...\n",
            "Preparing features and target...\n",
            "Filtering rare classes with fewer than 5 instances...\n",
            "Splitting data into training and test sets...\n",
            "Scaling features...\n",
            "Setting up cross-validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Kernel Loop:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Kernel: linear:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Folds: 0it [00:00, ?it/s]\u001b[A\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfMHRvZu8tsQ"
      },
      "source": [
        "### **6. Experiment with Decision Tree (DT) Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from joblib import Parallel, delayed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Define StratifiedKFold with 5 splits\n",
        "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "max_depth_vals = [5, 10]\n",
        "min_samples_split_vals = [2, 5]\n",
        "min_samples_leaf_vals = [1, 3]\n",
        "max_features_vals = ['sqrt', 'log2']\n",
        "max_leaf_nodes_vals = [None, 20]\n",
        "criteria = ['gini', 'entropy']\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "def evaluate_fold(X_train, X_val, y_train, y_val, max_depth, min_samples_split,\n",
        "                  min_samples_leaf, max_features, max_leaf_nodes, criterion):\n",
        "    dt_model = DecisionTreeClassifier(\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        max_leaf_nodes=max_leaf_nodes,\n",
        "        criterion=criterion,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train and predict\n",
        "    dt_model.fit(X_train, y_train)\n",
        "    y_pred = dt_model.predict(X_val)\n",
        "    y_prob = dt_model.predict_proba(X_val) if len(np.unique(y)) > 2 else None\n",
        "\n",
        "    # Calculate metrics with zero_division handling for precision/recall\n",
        "    fold_accuracy = accuracy_score(y_val, y_pred)\n",
        "    fold_precision = precision_score(y_val, y_pred, average='weighted', zero_division=1)\n",
        "    fold_recall = recall_score(y_val, y_pred, average='weighted', zero_division=1)\n",
        "    fold_f1 = f1_score(y_val, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "    # ROC AUC calculation for multiclass or binary\n",
        "    if y_prob is not None:\n",
        "        fold_auc = roc_auc_score(y_val, y_prob, average='weighted', multi_class='ovr')\n",
        "    else:\n",
        "        fold_auc = roc_auc_score(y_val, dt_model.predict_proba(X_val)[:, 1]) if len(np.unique(y)) == 2 else None\n",
        "\n",
        "    return fold_accuracy, fold_precision, fold_recall, fold_f1, fold_auc\n",
        "\n",
        "# Iterate over all combinations of parameters\n",
        "for max_depth in max_depth_vals:\n",
        "    for min_samples_split in min_samples_split_vals:\n",
        "        for min_samples_leaf in min_samples_leaf_vals:\n",
        "            for max_features in max_features_vals:\n",
        "                for max_leaf_nodes in max_leaf_nodes_vals:\n",
        "                    for criterion in criteria:\n",
        "                        # Parallelized Stratified 5-fold cross-validation\n",
        "                        metrics = Parallel(n_jobs=-1)(\n",
        "                            delayed(evaluate_fold)(\n",
        "                                X.iloc[train_index], X.iloc[test_index],\n",
        "                                y.iloc[train_index], y.iloc[test_index],\n",
        "                                max_depth, min_samples_split, min_samples_leaf,\n",
        "                                max_features, max_leaf_nodes, criterion\n",
        "                            )\n",
        "                            for train_index, test_index in strat_k_fold.split(X, y)\n",
        "                        )\n",
        "\n",
        "                        # Collect per-fold results for display\n",
        "                        fold_results = []\n",
        "                        for i, (acc, prec, rec, f1, auc) in enumerate(metrics):\n",
        "                            fold_results.append({\n",
        "                                'fold': i + 1,\n",
        "                                'accuracy': acc,\n",
        "                                'precision': prec,\n",
        "                                'recall': rec,\n",
        "                                'f1_score': f1,\n",
        "                                'auc_roc': auc\n",
        "                            })\n",
        "\n",
        "                        # Calculate average metrics for this combination\n",
        "                        avg_accuracy = np.mean([m[0] for m in metrics])\n",
        "                        avg_precision = np.mean([m[1] for m in metrics])\n",
        "                        avg_recall = np.mean([m[2] for m in metrics])\n",
        "                        avg_f1 = np.mean([m[3] for m in metrics])\n",
        "                        avg_auc = np.mean([m[4] for m in metrics if m[4] is not None])\n",
        "\n",
        "                        # Store results with per-fold details\n",
        "                        results.append({\n",
        "                            'max_depth': max_depth,\n",
        "                            'min_samples_split': min_samples_split,\n",
        "                            'min_samples_leaf': min_samples_leaf,\n",
        "                            'max_features': max_features,\n",
        "                            'max_leaf_nodes': max_leaf_nodes,\n",
        "                            'criterion': criterion,\n",
        "                            'fold_results': fold_results,\n",
        "                            'avg_accuracy': avg_accuracy,\n",
        "                            'avg_precision': avg_precision,\n",
        "                            'avg_recall': avg_recall,\n",
        "                            'avg_f1_score': avg_f1,\n",
        "                            'avg_auc_roc': avg_auc\n",
        "                        })\n",
        "\n",
        "# Convert results to a DataFrame and display\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display fold-level results for each parameter combination\n",
        "for result in results:\n",
        "    print(f\"Parameter Combination: {result['max_depth'], result['min_samples_split'], result['min_samples_leaf'], result['max_features'], result['max_leaf_nodes'], result['criterion']}\")\n",
        "    for fold in result['fold_results']:\n",
        "        print(f\"  Fold {fold['fold']}: Accuracy = {fold['accuracy']}, Precision = {fold['precision']}, Recall = {fold['recall']}, F1 = {fold['f1_score']}, AUC = {fold['auc_roc']}\")\n",
        "    print(\"Average Metrics - \", \"Accuracy:\", result['avg_accuracy'], \"Precision:\", result['avg_precision'], \"Recall:\", result['avg_recall'], \"F1 Score:\", result['avg_f1_score'], \"AUC:\", result['avg_auc_roc'])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Identify the best model based on the highest F1-Score (or Accuracy if F1 is unavailable)\n",
        "best_model_params = results_df.loc[results_df['avg_f1_score'].idxmax()] if 'avg_f1_score' in results_df else results_df.loc[results_df['avg_accuracy'].idxmax()]\n",
        "print(\"Best Model Parameters:\\n\", best_model_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdjaze2vushF",
        "outputId": "e2b78044-aebf-4499-ac15-607d6601efdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter Combination: (5, 2, 1, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9415488215488216 Recall: 0.9400000000000001 F1 Score: 0.9398830409356724 AUC: 0.9543333333333333\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9733333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.9596666666666668\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9354882154882155 Recall: 0.9333333333333333 F1 Score: 0.9331996658312448 AUC: 0.9549999999999998\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9444444444444445, Recall = 0.9333333333333333, F1 = 0.9326599326599326, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9377104377104377 Recall: 0.9333333333333333 F1 Score: 0.9330649856965646 AUC: 0.9549999999999998\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9415488215488216 Recall: 0.9400000000000001 F1 Score: 0.9398830409356724 AUC: 0.9543333333333333\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9733333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.9596666666666668\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9354882154882155 Recall: 0.9333333333333333 F1 Score: 0.9331996658312448 AUC: 0.9549999999999998\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 1, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9444444444444445, Recall = 0.9333333333333333, F1 = 0.9326599326599326, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9377104377104377 Recall: 0.9333333333333333 F1 Score: 0.9330649856965646 AUC: 0.9549999999999998\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 2, 3, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9693333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9646666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9693333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 1, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9646666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (5, 5, 3, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9415488215488216 Recall: 0.9400000000000001 F1 Score: 0.9398830409356724 AUC: 0.9550000000000001\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.9600000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9476094276094276 Recall: 0.9466666666666667 F1 Score: 0.9465664160401002 AUC: 0.96\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9444444444444445, Recall = 0.9333333333333333, F1 = 0.9326599326599326, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9377104377104377 Recall: 0.9333333333333333 F1 Score: 0.9330649856965646 AUC: 0.95\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9415488215488216 Recall: 0.9400000000000001 F1 Score: 0.9398830409356724 AUC: 0.9550000000000001\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.9600000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.95\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9476094276094276 Recall: 0.9466666666666667 F1 Score: 0.9465664160401002 AUC: 0.96\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 1, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9333333333333333, Precision = 0.9444444444444445, Recall = 0.9333333333333333, F1 = 0.9326599326599326, AUC = 0.95\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9333333333333333 Precision: 0.9377104377104377 Recall: 0.9333333333333333 F1 Score: 0.9330649856965646 AUC: 0.95\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 2, 3, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9693333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9646666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9693333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9716666666666668\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9466666666666667\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.948956228956229 Recall: 0.9466666666666667 F1 Score: 0.9465664160401003 AUC: 0.9636666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 1, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9483333333333335\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.925\n",
            "Average Metrics -  Accuracy: 0.9400000000000001 Precision: 0.9427609427609427 Recall: 0.9400000000000001 F1 Score: 0.9398496240601503 AUC: 0.9646666666666667\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'sqrt', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'sqrt', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'sqrt', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'sqrt', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'log2', None, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333335 Precision: 0.9550168350168351 Recall: 0.9533333333333335 F1 Score: 0.9532497911445279 AUC: 0.9760000000000002\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'log2', None, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.9983333333333334\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9166666666666666\n",
            "Average Metrics -  Accuracy: 0.9466666666666667 Precision: 0.9488215488215488 Recall: 0.9466666666666667 F1 Score: 0.9465329991645781 AUC: 0.967\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'log2', 20, 'gini')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9333333333333333, Precision = 0.9333333333333333, Recall = 0.9333333333333333, F1 = 0.9333333333333333, AUC = 0.9650000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9600000000000002 Precision: 0.9610774410774411 Recall: 0.9600000000000002 F1 Score: 0.9599331662489556 AUC: 0.9723333333333335\n",
            "\n",
            "\n",
            "Parameter Combination: (10, 5, 3, 'log2', 20, 'entropy')\n",
            "  Fold 1: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 2: Accuracy = 0.9666666666666667, Precision = 0.9696969696969696, Recall = 0.9666666666666667, F1 = 0.9665831244778613, AUC = 0.975\n",
            "  Fold 3: Accuracy = 0.9, Precision = 0.9023569023569025, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9450000000000001\n",
            "  Fold 4: Accuracy = 1.0, Precision = 1.0, Recall = 1.0, F1 = 1.0, AUC = 1.0\n",
            "  Fold 5: Accuracy = 0.9, Precision = 0.9023569023569024, Recall = 0.9, F1 = 0.8997493734335839, AUC = 0.9216666666666666\n",
            "Average Metrics -  Accuracy: 0.9533333333333334 Precision: 0.9548821548821549 Recall: 0.9533333333333334 F1 Score: 0.9532163742690057 AUC: 0.9683333333333334\n",
            "\n",
            "\n",
            "Best Model Parameters:\n",
            " max_depth                                                            5\n",
            "min_samples_split                                                    2\n",
            "min_samples_leaf                                                     3\n",
            "max_features                                                      sqrt\n",
            "max_leaf_nodes                                                    20.0\n",
            "criterion                                                         gini\n",
            "fold_results         [{'fold': 1, 'accuracy': 1.0, 'precision': 1.0...\n",
            "avg_accuracy                                                      0.96\n",
            "avg_precision                                                 0.961077\n",
            "avg_recall                                                        0.96\n",
            "avg_f1_score                                                  0.959933\n",
            "avg_auc_roc                                                   0.972333\n",
            "Name: 10, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-QanrV58tsQ"
      },
      "source": [
        "### **7. Experiment with Back Propagation Neural Network (BPNN) Classification Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "import warnings\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('cleaned_crime_data.csv').sample(1000, random_state=42)\n",
        "data = data.drop(columns=['Datetime','AREA NAME', 'LOCATION', 'Weapon Used Cd'])\n",
        "\n",
        "# Map 'Day of Week' to numbers\n",
        "day_of_week_mapping = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4,\n",
        "                       'Friday': 5, 'Saturday': 6, 'Sunday': 7}\n",
        "data['Day of Week'] = data['Day of Week'].map(day_of_week_mapping)\n",
        "\n",
        "# Map 'Time_of_Day' and 'Vict Sex'\n",
        "data['Time_of_Day'] = data['Time_of_Day'].map({'Day': 0, 'Night': 1})\n",
        "data['Vict Sex'] = data['Vict Sex'].map({'M': 1, 'X': 3, 'F': 2})\n",
        "\n",
        "# Encode 'Vict Descent' and fill missing values in 'Premis Cd'\n",
        "label_encoder = LabelEncoder()\n",
        "data['Vict Descent'] = label_encoder.fit_transform(data['Vict Descent'])\n",
        "\n",
        "# Fill missing values in 'Premis Cd'\n",
        "data['Premis Cd'] = data['Premis Cd'].fillna(data['Premis Cd'].mode()[0])\n",
        "\n",
        "# Initial feature and label setup\n",
        "X = data.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)\n",
        "y = data['Crm Cd']\n",
        "\n",
        "# Feature selection using RandomForestClassifier\n",
        "feature_selector = RandomForestClassifier(random_state=42)\n",
        "feature_selector.fit(X, y)\n",
        "\n",
        "# Select important features based on threshold\n",
        "selector = SelectFromModel(feature_selector, threshold=0.01, prefit=True)\n",
        "X_reduced = selector.transform(X)\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected features:\", selected_features)\n",
        "\n",
        "# Update X with only the selected features\n",
        "X = pd.DataFrame(X_reduced, columns=selected_features)\n",
        "\n",
        "# Filter out infrequent classes\n",
        "value_counts = y.value_counts()\n",
        "classes_to_keep = value_counts[value_counts >= 5].index\n",
        "data_filtered = data[data['Crm Cd'].isin(classes_to_keep)].reset_index(drop=True)\n",
        "\n",
        "# Determine sample size based on available data\n",
        "sample_size = min(1000, len(data_filtered))  # Ensure we don't sample more than available\n",
        "\n",
        "# Take a random sample from the filtered data\n",
        "data_sampled = data_filtered.sample(sample_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Define features and labels on the sampled data\n",
        "X = data_sampled.drop(['Crm Cd', 'Crm Cd Desc'], axis=1)\n",
        "y = data_sampled['Crm Cd']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "y_train_cat = to_categorical(LabelEncoder().fit_transform(y_train))\n",
        "y_test_cat = to_categorical(LabelEncoder().fit_transform(y_test))\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Parameter grid for BPNN\n",
        "param_grid = {\n",
        "    'hidden_layers': [1, 2],\n",
        "    'neurons': [10, 20],\n",
        "    'learning_rate': [0.01, 0.001],\n",
        "    'epochs': [10, 100, 500],\n",
        "    'activation_function': ['relu_sigmoid', 'sigmoid_sigmoid']\n",
        "}\n",
        "\n",
        "# Function to build model\n",
        "def build_model(hidden_layers, neurons, learning_rate, activation_function):\n",
        "    model = Sequential()\n",
        "    for _ in range(hidden_layers):\n",
        "        if activation_function == 'relu_sigmoid':\n",
        "            model.add(Dense(neurons, activation='relu'))\n",
        "        else:\n",
        "            model.add(Dense(neurons, activation='sigmoid'))\n",
        "\n",
        "    # Change the output layer for binary classification\n",
        "    if y_train_cat.shape[1] == 2:\n",
        "        model.add(Dense(1, activation='sigmoid'))  # Single output neuron with sigmoid activation\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        model.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
        "        loss = 'categorical_crossentropy'\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss=loss,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Set the number of splits to a minimum of 2 to avoid the ValueError\n",
        "n_splits = max(2, min(5, value_counts.min()))\n",
        "strat_k_fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Store results for each parameter combination\n",
        "results = []\n",
        "\n",
        "# Iterate over each parameter combination\n",
        "for hidden_layers in param_grid['hidden_layers']:\n",
        "    for neurons in param_grid['neurons']:\n",
        "        for learning_rate in param_grid['learning_rate']:\n",
        "            for epochs in param_grid['epochs']:\n",
        "                for activation_function in param_grid['activation_function']:\n",
        "                    # Store cross-validation metrics\n",
        "                    accuracies, precisions, recalls, f1_scores, auc_rocs = [], [], [], [], []\n",
        "\n",
        "                    for train_idx, val_idx in strat_k_fold.split(X_train, y_train):\n",
        "                        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "                        y_fold_train, y_fold_val = y_train_cat[train_idx], y_train_cat[val_idx]\n",
        "\n",
        "                        # Build and train model\n",
        "                        model = build_model(hidden_layers, neurons, learning_rate, activation_function)\n",
        "                        model.fit(X_fold_train, y_fold_train, epochs=epochs, verbose = 0)\n",
        "\n",
        "                        # Predict and calculate metrics\n",
        "                        y_pred = model.predict(X_fold_val)\n",
        "                        y_pred = np.nan_to_num(y_pred)\n",
        "\n",
        "                        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "                        y_val_classes = np.argmax(y_fold_val, axis=1)\n",
        "\n",
        "                        # Calculate basic metrics\n",
        "                        accuracy = accuracy_score(y_val_classes, y_pred_classes)\n",
        "                        precision = precision_score(y_val_classes, y_pred_classes, average='weighted', zero_division=0)\n",
        "                        recall = recall_score(y_val_classes, y_pred_classes, average='weighted')\n",
        "                        f1 = f1_score(y_val_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "                        # Check if multiple classes are present in validation set for ROC AUC\n",
        "                        if len(np.unique(y_val_classes)) > 1:\n",
        "                            auc = roc_auc_score(y_fold_val, y_pred, multi_class='ovo', average='weighted')\n",
        "                        else:\n",
        "                            auc = np.nan\n",
        "\n",
        "                        # Append metrics to lists\n",
        "                        accuracies.append(accuracy)\n",
        "                        precisions.append(precision)\n",
        "                        recalls.append(recall)\n",
        "                        f1_scores.append(f1)\n",
        "                        auc_rocs.append(auc)\n",
        "\n",
        "                        # Clear session to reset the model\n",
        "                        K.clear_session()\n",
        "\n",
        "                    # Store results\n",
        "                    results.append({\n",
        "                        'hidden_layers': hidden_layers,\n",
        "                        'neurons': neurons,\n",
        "                        'learning_rate': learning_rate,\n",
        "                        'epochs': epochs,\n",
        "                        'activation_function': activation_function,\n",
        "                        'accuracy': np.mean(accuracies),\n",
        "                        'precision': np.mean(precisions),\n",
        "                        'recall': np.mean(recalls),\n",
        "                        'f1_score': np.mean(f1_scores),\n",
        "                        # Calculate mean AUC if there are valid (non-NaN) values, otherwise set to NaN\n",
        "                        'auc_roc': np.nanmean(auc_rocs) if np.any(~np.isnan(auc_rocs)) else np.nan\n",
        "                    })\n",
        "\n",
        "\n",
        "# Convert results to DataFrame and find the best model\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nBPNN Cross-Validation Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# Select the best model parameters based on the highest F1 score\n",
        "best_model_params = results_df.loc[results_df['f1_score'].idxmax()]\n",
        "print(\"\\nBest Model Parameters:\\n\", best_model_params)\n",
        "\n",
        "# Train the best model on the entire training set\n",
        "best_model = build_model(\n",
        "    int(best_model_params['hidden_layers']),\n",
        "    int(best_model_params['neurons']),\n",
        "    float(best_model_params['learning_rate']),\n",
        "    best_model_params['activation_function']\n",
        ")\n",
        "best_model.fit(X_train, y_train_cat, epochs=int(best_model_params['epochs']), verbose = 0)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "y_test_pred = np.nan_to_num(y_test_pred)\n",
        "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# Calculate test metrics\n",
        "test_accuracy = accuracy_score(y_test_classes, y_test_pred_classes)\n",
        "test_precision = precision_score(y_test_classes, y_test_pred_classes, average='weighted', zero_division=0)\n",
        "test_recall = recall_score(y_test_classes, y_test_pred_classes, average='weighted')\n",
        "test_f1_score = f1_score(y_test_classes, y_test_pred_classes, average='weighted')\n",
        "\n",
        "# Handle the case with only one class in y_true for AUC ROC calculation\n",
        "if len(np.unique(y_test_classes)) > 1:\n",
        "    test_auc_roc = roc_auc_score(y_test_cat, y_test_pred, multi_class='ovo', average='weighted')\n",
        "else:\n",
        "    test_auc_roc = np.nan  # Set AUC as NaN if only one class is present\n",
        "\n",
        "print(f\"\\nTest Set Performance:\\nAccuracy: {test_accuracy:.4f}\\nPrecision: {test_precision:.4f}\\nRecall: {test_recall:.4f}\\nF1 Score: {test_f1_score:.4f}\\nAUC ROC: {test_auc_roc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Japjv89L4B79",
        "outputId": "c48c3077-9201-41cb-f87e-bf7c2424ba41"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: Index(['Day of Week', 'Month', 'Hour', 'Year', 'Time_of_Day', 'AREA', 'LAT',\n",
            "       'LON', 'Rpt Dist No', 'Premis Cd', 'Vict Age', 'Vict Age Standardized',\n",
            "       'Vict Sex', 'Vict Descent'],\n",
            "      dtype='object')\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\n",
            "BPNN Cross-Validation Results:\n",
            "    hidden_layers  neurons  learning_rate  epochs activation_function  \\\n",
            "0               1       10          0.010      10        relu_sigmoid   \n",
            "1               1       10          0.010      10     sigmoid_sigmoid   \n",
            "2               1       10          0.010     100        relu_sigmoid   \n",
            "3               1       10          0.010     100     sigmoid_sigmoid   \n",
            "4               1       10          0.010     500        relu_sigmoid   \n",
            "5               1       10          0.010     500     sigmoid_sigmoid   \n",
            "6               1       10          0.001      10        relu_sigmoid   \n",
            "7               1       10          0.001      10     sigmoid_sigmoid   \n",
            "8               1       10          0.001     100        relu_sigmoid   \n",
            "9               1       10          0.001     100     sigmoid_sigmoid   \n",
            "10              1       10          0.001     500        relu_sigmoid   \n",
            "11              1       10          0.001     500     sigmoid_sigmoid   \n",
            "12              1       20          0.010      10        relu_sigmoid   \n",
            "13              1       20          0.010      10     sigmoid_sigmoid   \n",
            "14              1       20          0.010     100        relu_sigmoid   \n",
            "15              1       20          0.010     100     sigmoid_sigmoid   \n",
            "16              1       20          0.010     500        relu_sigmoid   \n",
            "17              1       20          0.010     500     sigmoid_sigmoid   \n",
            "18              1       20          0.001      10        relu_sigmoid   \n",
            "19              1       20          0.001      10     sigmoid_sigmoid   \n",
            "20              1       20          0.001     100        relu_sigmoid   \n",
            "21              1       20          0.001     100     sigmoid_sigmoid   \n",
            "22              1       20          0.001     500        relu_sigmoid   \n",
            "23              1       20          0.001     500     sigmoid_sigmoid   \n",
            "24              2       10          0.010      10        relu_sigmoid   \n",
            "25              2       10          0.010      10     sigmoid_sigmoid   \n",
            "26              2       10          0.010     100        relu_sigmoid   \n",
            "27              2       10          0.010     100     sigmoid_sigmoid   \n",
            "28              2       10          0.010     500        relu_sigmoid   \n",
            "29              2       10          0.010     500     sigmoid_sigmoid   \n",
            "30              2       10          0.001      10        relu_sigmoid   \n",
            "31              2       10          0.001      10     sigmoid_sigmoid   \n",
            "32              2       10          0.001     100        relu_sigmoid   \n",
            "33              2       10          0.001     100     sigmoid_sigmoid   \n",
            "34              2       10          0.001     500        relu_sigmoid   \n",
            "35              2       10          0.001     500     sigmoid_sigmoid   \n",
            "36              2       20          0.010      10        relu_sigmoid   \n",
            "37              2       20          0.010      10     sigmoid_sigmoid   \n",
            "38              2       20          0.010     100        relu_sigmoid   \n",
            "39              2       20          0.010     100     sigmoid_sigmoid   \n",
            "40              2       20          0.010     500        relu_sigmoid   \n",
            "41              2       20          0.010     500     sigmoid_sigmoid   \n",
            "42              2       20          0.001      10        relu_sigmoid   \n",
            "43              2       20          0.001      10     sigmoid_sigmoid   \n",
            "44              2       20          0.001     100        relu_sigmoid   \n",
            "45              2       20          0.001     100     sigmoid_sigmoid   \n",
            "46              2       20          0.001     500        relu_sigmoid   \n",
            "47              2       20          0.001     500     sigmoid_sigmoid   \n",
            "\n",
            "    accuracy  precision    recall  f1_score   auc_roc  \n",
            "0   0.247706   0.152865  0.247706  0.179508  0.726048  \n",
            "1   0.224771   0.091193  0.224771  0.123381  0.706872  \n",
            "2   0.195719   0.169958  0.195719  0.180031  0.703442  \n",
            "3   0.250765   0.212935  0.250765  0.223829  0.736469  \n",
            "4   0.185015   0.192319  0.185015  0.181289  0.695029  \n",
            "5   0.201835   0.193154  0.201835  0.193476  0.712495  \n",
            "6   0.119266   0.068855  0.119266  0.074170  0.557180  \n",
            "7   0.073394   0.013005  0.073394  0.020967  0.535349  \n",
            "8   0.247706   0.160988  0.247706  0.181571  0.714274  \n",
            "9   0.209480   0.105598  0.209480  0.107114  0.689383  \n",
            "10  0.221713   0.191419  0.221713  0.199395  0.725990  \n",
            "11  0.230887   0.167395  0.230887  0.179022  0.739243  \n",
            "12  0.233945   0.168683  0.233945  0.190026  0.720031  \n",
            "13  0.241590   0.129526  0.241590  0.159499  0.729675  \n",
            "14  0.189602   0.172883  0.189602  0.178088  0.700935  \n",
            "15  0.230887   0.205112  0.230887  0.213767  0.724396  \n",
            "16  0.166667   0.179028  0.166667  0.170015  0.682744  \n",
            "17  0.188073   0.176347  0.188073  0.180680  0.687888  \n",
            "18  0.174312   0.080455  0.174312  0.102728  0.612951  \n",
            "19  0.140673   0.089390  0.140673  0.083710  0.576725  \n",
            "20  0.255352   0.185449  0.255352  0.210995  0.722861  \n",
            "21  0.223242   0.119550  0.223242  0.141462  0.719723  \n",
            "22  0.198777   0.178891  0.198777  0.186247  0.702156  \n",
            "23  0.246177   0.182528  0.246177  0.207952  0.733671  \n",
            "24  0.217125   0.126514  0.217125  0.153801  0.677997  \n",
            "25  0.183486   0.049634  0.183486  0.076893  0.653373  \n",
            "26  0.177370   0.165145  0.177370  0.169515  0.690563  \n",
            "27  0.246177   0.179822  0.246177  0.196890  0.743749  \n",
            "28  0.177370   0.185596  0.177370  0.178711  0.666985  \n",
            "29  0.204893   0.190323  0.204893  0.192367  0.707702  \n",
            "30  0.082569   0.027713  0.082569  0.037365  0.551980  \n",
            "31  0.091743   0.013151  0.091743  0.021310  0.590375  \n",
            "32  0.230887   0.154629  0.230887  0.178530  0.713818  \n",
            "33  0.186544   0.047799  0.186544  0.074887  0.680816  \n",
            "34  0.214067   0.187386  0.214067  0.192299  0.704243  \n",
            "35  0.232416   0.141346  0.232416  0.172221  0.742000  \n",
            "36  0.247706   0.185686  0.247706  0.206741  0.719620  \n",
            "37  0.217125   0.098732  0.217125  0.121787  0.708940  \n",
            "38  0.171254   0.173854  0.171254  0.169848  0.685780  \n",
            "39  0.223242   0.185318  0.223242  0.197880  0.737071  \n",
            "40  0.169725   0.169427  0.169725  0.167772  0.676772  \n",
            "41  0.189602   0.186658  0.189602  0.185676  0.695466  \n",
            "42  0.180428   0.085362  0.180428  0.097013  0.597927  \n",
            "43  0.128440   0.016497  0.128440  0.029238  0.551034  \n",
            "44  0.235474   0.177647  0.235474  0.199083  0.707924  \n",
            "45  0.218654   0.126868  0.218654  0.123217  0.696360  \n",
            "46  0.177370   0.170772  0.177370  0.172768  0.696611  \n",
            "47  0.230887   0.174067  0.230887  0.194544  0.742703  \n",
            "\n",
            "Best Model Parameters:\n",
            " hidden_layers                        1\n",
            "neurons                             10\n",
            "learning_rate                     0.01\n",
            "epochs                             100\n",
            "activation_function    sigmoid_sigmoid\n",
            "accuracy                      0.250765\n",
            "precision                     0.212935\n",
            "recall                        0.250765\n",
            "f1_score                      0.223829\n",
            "auc_roc                       0.736469\n",
            "Name: 3, dtype: object\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\n",
            "Test Set Performance:\n",
            "Accuracy: 0.2171\n",
            "Precision: 0.1632\n",
            "Recall: 0.2171\n",
            "F1 Score: 0.1821\n",
            "AUC ROC: 0.7292\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8iZpFzog8tsP",
        "CEDJDHHW8tsP",
        "loXLSMK58tsP"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}